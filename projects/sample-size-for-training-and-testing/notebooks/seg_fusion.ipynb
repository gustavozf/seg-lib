{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a56376-5973-44a0-a64b-cf37030cf64a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'seg_lib_env (Python 3.10.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n seg_lib_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import measure\n",
    "\n",
    "from seg_lib.dataloaders.sam_dataset import SamGeneralDataset\n",
    "from seg_lib.eval.metrics import Metrics\n",
    "from seg_lib.eval.fusion import LogitsFusion\n",
    "from seg_lib.io.files import read_json\n",
    "from seg_lib.models.cafe_net.pvt import CAFE\n",
    "from seg_lib.models.pvt_v2 import SegPVT\n",
    "from seg_lib.models.selector import predictor_selector\n",
    "from seg_lib.models.normalizer import Normalizer\n",
    "from seg_lib.prompt import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf7d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.5\n",
    "# total number of parallel workers used in the dataloader\n",
    "N_CPUS = os.cpu_count()\n",
    "N_GPUS = torch.cuda.device_count()\n",
    "DEVICE = 'cuda' if N_GPUS > 0 else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36212e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'E:\\\\UNIPD\\\\SAM'\n",
    "TEST_PATH = f'{BASE_PATH}/data/test'\n",
    "TEST_DESCRIPTOR = 'metadata/ribs_full.csv'\n",
    "BASE_WEIGHTS = f'{BASE_PATH}/pretrained_models/pvt_v2_b2.pth'\n",
    "MODELS_SETS = [\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_small_da2',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_small_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_da2',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/ribs_cafe_da1',\n",
    "    ]\n",
    "]\n",
    "SAM_WEIGHTS = f'{BASE_PATH}/pretrained_models/sam_vit_b_01ec64.pth'\n",
    "SAM_MODELS = [\n",
    "    f'{BASE_PATH}/outputs/v0_9_0_small_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/v0_9_0_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/v0_9_0_small_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/v0_9_0_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/v1_1_0_small/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/v1_1_0/best_SAMUS.pth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_type: str, ckpt_path: str):\n",
    "    if model_type == 'pvt':\n",
    "        return SegPVT(backbone_ckpt_path=ckpt_path)\n",
    "    \n",
    "    return CAFE(pvtv2_path=ckpt_path)\n",
    "\n",
    "def get_model(ckpt_path: str, model_path: str, model_type: str = 'pvt'):\n",
    "    model = select_model(model_type, ckpt_path)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac66ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "        data_path: str,\n",
    "        data_desc_path: str,\n",
    "        batch_size: int = 8,\n",
    "        embedding_size: int = 128,\n",
    "        input_size: int = 352):\n",
    "    csv_path = os.path.join(data_path, data_desc_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    test_split = 'test' if 'test' in df['split'].unique() else 'val'\n",
    "    del df\n",
    "\n",
    "    test_dataset = SamGeneralDataset(\n",
    "        data_path,\n",
    "        split=test_split, \n",
    "        point_sampler=None,\n",
    "        df_file_path=data_desc_path,\n",
    "        img_size=input_size,\n",
    "        embedding_size=embedding_size,\n",
    "        prompt=None,\n",
    "        read_img_as_grayscale=False)\n",
    "    \n",
    "    return DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size * max(1, N_GPUS),\n",
    "        shuffle=False,\n",
    "        num_workers=N_CPUS,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0692024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_preds(preds):\n",
    "    if isinstance(preds, tuple):\n",
    "        final_preds = preds[0]\n",
    "        for i in range(1, len(preds)):\n",
    "            final_preds += preds[i]\n",
    "        preds = final_preds\n",
    "\n",
    "    return preds\n",
    "\n",
    "def eval(test_dataset, model_1, model_2):\n",
    "    metrics = Metrics()\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "    pred_masks = []\n",
    "    pred_logits = []\n",
    "    file_names = []\n",
    "    \n",
    "    data_config = {'dtype': torch.float32, 'device': DEVICE}\n",
    "    for batch in tqdm(test_dataset):\n",
    "        imgs = batch['image'].to(**data_config)\n",
    "        labels = batch['label'].to(**data_config)\n",
    "        orig_sizes = np.array(\n",
    "            list(zip(*batch['original_img_size']) ), dtype=int\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _start = time.time()\n",
    "            preds_1 = model_1(imgs)\n",
    "            preds_2 = model_2(imgs)\n",
    "            _end = time.time()\n",
    "\n",
    "        latency_p_batch.append(_end - _start)\n",
    "        batch_sizes.append(imgs.shape[0])\n",
    "\n",
    "        preds_1 = flatten_preds(preds_1)\n",
    "        preds_2 = flatten_preds(preds_2)\n",
    "        preds = (preds_1 + preds_2) / 2\n",
    "        \n",
    "        logits = preds.sigmoid().detach().numpy()[:, 0, :, :]\n",
    "        bin_masks = (logits > TH).astype('uint8')\n",
    "        labels = labels.detach().numpy()[:, 0, :, :].astype('uint8')\n",
    "        for i in range(bin_masks.shape[0]):\n",
    "            bin_mask = cv2.resize(\n",
    "                bin_masks[i], orig_sizes[i], cv2.INTER_NEAREST\n",
    "            )\n",
    "            label = cv2.resize(labels[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            metrics.step(bin_mask, label)\n",
    "\n",
    "            logits_i = cv2.resize(logits[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            pred_logits.append(logits_i)\n",
    "            pred_masks.append(bin_mask)\n",
    "            file_names.append(batch['img_name'][i])\n",
    "\n",
    "    metrics = {\n",
    "        **metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "    preds = {\n",
    "        file_names[i]: {\n",
    "            'logits': pred_logits[i],\n",
    "            'mask': pred_masks[i]\n",
    "        }\n",
    "        for i in range(len(file_names))\n",
    "    }\n",
    "    return metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aecac580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(i_row: dict):\n",
    "    base_path = os.path.join(TEST_PATH, i_row['subset']) \n",
    "    img_path = os.path.join(base_path, 'img', i_row['img_name'])\n",
    "    label_path = os.path.join(base_path, 'label', i_row['label_name'])\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        raise ValueError(f'Image does not exist on disk: {img_path}')\n",
    "    if not os.path.exists(label_path):\n",
    "        raise ValueError(f'Label does not exist on disk: {label_path}')\n",
    "\n",
    "    # load the image (H, W, 3) and convert it from BGR to RGB\n",
    "    image = cv2.imread(img_path, 1)[:, :, ::-1]\n",
    "    # read the mask as (H, W), grayscale\n",
    "    mask = cv2.imread(label_path, 0)\n",
    "    mask[mask > 1] = 1\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def predict_sam(data_df, predictor, sampler, seg_preds):\n",
    "    sam_metrics = Metrics()\n",
    "    preds = {}\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "\n",
    "    for _, row in tqdm(data_df.iterrows(), total=data_df.shape[0]):\n",
    "        img, label = read_img(row)        \n",
    "        mask_of_blobs = measure.label(seg_preds[row['img_name']]['mask'])\n",
    "        input_point, input_label = sampler.sample(\n",
    "            mask_of_blobs, seg_preds[row['img_name']]['mask']\n",
    "        )\n",
    "\n",
    "        _start = time.time()\n",
    "        predictor.set_image(img)\n",
    "        sam_logits, iou_scores, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=False,\n",
    "            return_logits=True\n",
    "        )\n",
    "        _end = time.time()\n",
    "        batch_sizes.append(1)\n",
    "        latency_p_batch.append(_end - _start)\n",
    "\n",
    "        logits =  sam_logits[np.argmax(iou_scores)]\n",
    "        binary_mask = logits > 0.0\n",
    "        sam_metrics.step(binary_mask, label)\n",
    "\n",
    "        preds[row['img_name']] = {\n",
    "            'label': label,\n",
    "            'logits': Normalizer.sigmoid(logits).astype(np.float32)\n",
    "        }\n",
    "\n",
    "    sam_metrics = {\n",
    "        **sam_metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "\n",
    "    return sam_metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e389bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse(preds, sam_preds):\n",
    "    fusion_metrics = Metrics()\n",
    "    fusion_preds = {}\n",
    "    for img_name in preds:\n",
    "        fusion = LogitsFusion.apply(\n",
    "            preds[img_name]['logits'],\n",
    "            sam_preds[img_name]['logits'],\n",
    "            method='default')\n",
    "        fusion_preds[img_name] = { 'logits': fusion }\n",
    "        fusion_metrics.step(fusion > TH, sam_preds[img_name]['label'])\n",
    "    \n",
    "    return fusion_metrics.get_results(), fusion_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289190df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(TEST_PATH, TEST_DESCRIPTOR))\n",
    "test_ds = get_dataset(\n",
    "    TEST_PATH,\n",
    "    TEST_DESCRIPTOR,\n",
    "    batch_size=8,\n",
    "    embedding_size=128,\n",
    "    input_size=352)\n",
    "sampler = Sampler(\n",
    "    sampling_step=50,\n",
    "    min_blob_count=10,\n",
    "    mode='grid',\n",
    "    erode_grid='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4681b0-b891-4118-9dbc-fe890ff267c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds = []\n",
    "full_sam_preds = []\n",
    "full_fusion_preds = []\n",
    "\n",
    "for i in range(len(MODELS_SETS)):\n",
    "    print(MODELS_SETS[i])\n",
    "    pvt_path = MODELS_SETS[i][0]\n",
    "    cafe_path = MODELS_SETS[i][1]\n",
    "\n",
    "    pvt_config = read_json(os.path.join(pvt_path, 'config.json'))\n",
    "    cafe_config = read_json(os.path.join(cafe_path, 'config.json'))\n",
    "\n",
    "    pvt_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(pvt_path, f\"best_{pvt_config['model_type']}.pth\"),\n",
    "        model_type='pvt')\n",
    "    cafe_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(cafe_path, f\"best_{cafe_config['model_type']}.pth\"),\n",
    "        model_type='cafe')\n",
    "    predictor = predictor_selector(\n",
    "        model_topology='SAMUS',\n",
    "        checkpoint_path=[SAM_WEIGHTS, SAM_MODELS[i]],\n",
    "        model_type='vit_b',\n",
    "        device=DEVICE)\n",
    "    \n",
    "    metrics, preds = eval(test_ds, pvt_model, cafe_model)\n",
    "    print('Seg. Metrics', metrics)\n",
    "    sam_metrics, sam_preds = predict_sam(test_df, predictor, sampler, preds)\n",
    "    print('SAM Metrics', sam_metrics)\n",
    "    fusion_metrics, fusion_preds = fuse(preds, sam_preds)\n",
    "    print('Fusion Metrics', fusion_metrics)\n",
    "\n",
    "    full_preds.append(preds)\n",
    "    full_sam_preds.append(sam_preds)\n",
    "    full_fusion_preds.append(fusion_preds)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08031ba",
   "metadata": {},
   "source": [
    "### Late Ensemble Model Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c435465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "small_da1_preds = full_preds[0]\n",
    "small_da2_preds = full_preds[2]\n",
    "small_fus_preds = {\n",
    "    _k: {\n",
    "        **small_da1_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_preds[_k]['logits'] + small_da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}\n",
    "\n",
    "small_da1_sam_preds = full_sam_preds[0]\n",
    "small_da2_sam_preds = full_sam_preds[2]\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_sam_preds[_k]['logits']\n",
    "                + small_da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in small_da1_sam_preds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_metrics, small_da3_preds = fuse(small_fus_preds, small_da1_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9af5765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "da1_preds = full_preds[1]\n",
    "da2_preds = full_preds[3]\n",
    "fus_preds = {\n",
    "    _k: {\n",
    "        **da1_preds[_k],\n",
    "        'logits': (\n",
    "            da1_preds[_k]['logits'] + da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in da1_preds\n",
    "}\n",
    "\n",
    "da1_sam_preds = full_sam_preds[1]\n",
    "da2_sam_preds = full_sam_preds[3]\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            da1_sam_preds[_k]['logits']\n",
    "                + da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_metrics, da3_preds = fuse(fus_preds, fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a053a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samus_path = f'{BASE_PATH}/outputs/train/v1_1_0_small/best_SAMUS.pth'\n",
    "predictor = predictor_selector(\n",
    "    model_topology='SAMUS',\n",
    "    checkpoint_path=[SAM_WEIGHTS, samus_path],\n",
    "    model_type='vit_b',\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e819f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_metrics, small_sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, small_fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_metrics, sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_metrics, fusion_preds = fuse(fus_preds, sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c33ec996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMUS 1+2+3\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            da1_sam_preds[_k]['logits'],\n",
    "            da2_sam_preds[_k]['logits'],\n",
    "            sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            small_da1_sam_preds[_k]['logits'],\n",
    "            small_da2_sam_preds[_k]['logits'],\n",
    "            small_sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
