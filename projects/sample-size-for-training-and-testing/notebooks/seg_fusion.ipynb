{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a56376-5973-44a0-a64b-cf37030cf64a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/__init__.py:1755\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \n\u001b[1;32m   1754\u001b[0m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[0;32m-> 1755\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _StorageBase\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/functional.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lowrank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svd_lowrank, pca_lowrank\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[1;32m     14\u001b[0m     handle_torch_function)\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/nn/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[1;32m      5\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[1;32m      6\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/nn/modules/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[1;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[1;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Threshold, ReLU, Hardtanh, ReLU6, Sigmoid, Tanh, \\\n\u001b[1;32m      7\u001b[0m     Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GELU, Hardshrink, LeakyReLU, LogSigmoid, \\\n\u001b[1;32m      8\u001b[0m     Softplus, Softshrink, MultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU, GLU, \\\n\u001b[1;32m      9\u001b[0m     Hardsigmoid, Hardswish, SiLU, Mish\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/nn/modules/linear.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter, UninitializedParameter\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/nn/functional.py:25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# The JIT doesn't understand Union, nor torch.dtype here\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     DType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_jit_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[1;32m     28\u001b[0m     handle_torch_function)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _reduction \u001b[38;5;28;01mas\u001b[39;00m _Reduction\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/_jit_internal.py:46\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Explicitly ask to import `torch.distributed.__init__` first.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrpc\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mangling\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpackage_mangling\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_awaits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Await\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Await \u001b[38;5;28;01mas\u001b[39;00m CAwait, Future \u001b[38;5;28;01mas\u001b[39;00m CFuture\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/package/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mis_from_package\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_from_package\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_structure_representation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Directory\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglob_group\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobGroup\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/package/analyze/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfind_first_use_of_broken_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_first_use_of_broken_modules\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrace_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trace_dependencies\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/package/analyze/find_first_use_of_broken_modules.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage_exporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PackagingError\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfind_first_use_of_broken_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_first_use_of_broken_modules\u001b[39m(exc: PackagingError) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]:\n",
      "File \u001b[0;32m~/miniconda3/envs/doc/lib/python3.11/site-packages/torch/package/package_exporter.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_digraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiGraph\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_importlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _normalize_path\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mangling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m demangle, is_mangled\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_package_pickler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_pickler\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stdlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_stdlib_module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import measure\n",
    "\n",
    "from seg_lib.dataloaders.sam_dataset import SamGeneralDataset\n",
    "from seg_lib.eval.metrics import Metrics\n",
    "from seg_lib.eval.fusion import LogitsFusion\n",
    "from seg_lib.io.files import read_json\n",
    "from seg_lib.models.cafe_net.pvt import CAFE\n",
    "from seg_lib.models.pvt_v2 import SegPVT\n",
    "from seg_lib.models.selector import predictor_selector\n",
    "from seg_lib.models.normalizer import Normalizer\n",
    "from seg_lib.prompt import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf7d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.5\n",
    "# total number of parallel workers used in the dataloader\n",
    "N_CPUS = os.cpu_count()\n",
    "N_GPUS = torch.cuda.device_count()\n",
    "DEVICE = 'cuda' if N_GPUS > 0 else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36212e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'E:\\\\UNIPD\\\\SAM'\n",
    "TEST_PATH = f'{BASE_PATH}/data/test'\n",
    "TEST_DESCRIPTOR = 'metadata/ribs_test_old.csv'\n",
    "BASE_WEIGHTS = f'{BASE_PATH}/pretrained_models/pvt_v2_b2.pth'\n",
    "MODELS_SETS = [\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da2',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da2',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da1',\n",
    "    ]\n",
    "]\n",
    "SAM_WEIGHTS = f'{BASE_PATH}/pretrained_models/sam_vit_b_01ec64.pth'\n",
    "SAM_MODELS = [\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_small_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_small_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v1_1_0_small/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v1_1_0/best_SAMUS.pth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_type: str, ckpt_path: str):\n",
    "    if model_type == 'pvt':\n",
    "        return SegPVT(backbone_ckpt_path=ckpt_path)\n",
    "    \n",
    "    return CAFE(pvtv2_path=ckpt_path)\n",
    "\n",
    "def get_model(ckpt_path: str, model_path: str, model_type: str = 'pvt'):\n",
    "    model = select_model(model_type, ckpt_path)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac66ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "        data_path: str,\n",
    "        data_desc_path: str,\n",
    "        batch_size: int = 8,\n",
    "        embedding_size: int = 128,\n",
    "        input_size: int = 352):\n",
    "    csv_path = os.path.join(data_path, data_desc_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    test_split = 'test' if 'test' in df['split'].unique() else 'val'\n",
    "    del df\n",
    "\n",
    "    test_dataset = SamGeneralDataset(\n",
    "        data_path,\n",
    "        split=test_split, \n",
    "        point_sampler=None,\n",
    "        df_file_path=data_desc_path,\n",
    "        img_size=input_size,\n",
    "        embedding_size=embedding_size,\n",
    "        prompt=None,\n",
    "        read_img_as_grayscale=False)\n",
    "    \n",
    "    return DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size * max(1, N_GPUS),\n",
    "        shuffle=False,\n",
    "        num_workers=N_CPUS,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0692024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_preds(preds):\n",
    "    if isinstance(preds, tuple):\n",
    "        final_preds = preds[0]\n",
    "        for i in range(1, len(preds)):\n",
    "            final_preds += preds[i]\n",
    "        preds = final_preds\n",
    "\n",
    "    return preds\n",
    "\n",
    "def eval(test_dataset, model_1, model_2):\n",
    "    metrics = Metrics()\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "    pred_masks = []\n",
    "    pred_logits = []\n",
    "    file_names = []\n",
    "    \n",
    "    data_config = {'dtype': torch.float32, 'device': DEVICE}\n",
    "    for batch in tqdm(test_dataset):\n",
    "        imgs = batch['image'].to(**data_config)\n",
    "        labels = batch['label'].to(**data_config)\n",
    "        orig_sizes = np.array(\n",
    "            list(zip(*batch['original_img_size']) ), dtype=int\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _start = time.time()\n",
    "            preds_1 = model_1(imgs)\n",
    "            preds_2 = model_2(imgs)\n",
    "            _end = time.time()\n",
    "\n",
    "        latency_p_batch.append(_end - _start)\n",
    "        batch_sizes.append(imgs.shape[0])\n",
    "\n",
    "        preds_1 = flatten_preds(preds_1)\n",
    "        preds_2 = flatten_preds(preds_2)\n",
    "        preds = (preds_1 + preds_2) / 2\n",
    "        \n",
    "        logits = preds.sigmoid().detach().numpy()[:, 0, :, :]\n",
    "        bin_masks = (logits > TH).astype('uint8')\n",
    "        labels = labels.detach().numpy()[:, 0, :, :].astype('uint8')\n",
    "        for i in range(bin_masks.shape[0]):\n",
    "            bin_mask = cv2.resize(\n",
    "                bin_masks[i], orig_sizes[i], cv2.INTER_NEAREST\n",
    "            )\n",
    "            label = cv2.resize(labels[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            metrics.step(bin_mask, label)\n",
    "\n",
    "            logits_i = cv2.resize(logits[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            pred_logits.append(logits_i)\n",
    "            pred_masks.append(bin_mask)\n",
    "            file_names.append(batch['img_name'][i])\n",
    "\n",
    "    metrics = {\n",
    "        **metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "    preds = {\n",
    "        file_names[i]: {\n",
    "            'logits': pred_logits[i],\n",
    "            'mask': pred_masks[i]\n",
    "        }\n",
    "        for i in range(len(file_names))\n",
    "    }\n",
    "    return metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aecac580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(i_row: dict):\n",
    "    base_path = os.path.join(TEST_PATH, i_row['subset']) \n",
    "    img_path = os.path.join(base_path, 'img', i_row['img_name'])\n",
    "    label_path = os.path.join(base_path, 'label', i_row['label_name'])\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        raise ValueError(f'Image does not exist on disk: {img_path}')\n",
    "    if not os.path.exists(label_path):\n",
    "        raise ValueError(f'Label does not exist on disk: {label_path}')\n",
    "\n",
    "    # load the image (H, W, 3) and convert it from BGR to RGB\n",
    "    image = cv2.imread(img_path, 1)[:, :, ::-1]\n",
    "    # read the mask as (H, W), grayscale\n",
    "    mask = cv2.imread(label_path, 0)\n",
    "    mask[mask > 1] = 1\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def predict_sam(data_df, predictor, sampler, seg_preds):\n",
    "    sam_metrics = Metrics()\n",
    "    preds = {}\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "\n",
    "    for _, row in tqdm(data_df.iterrows(), total=data_df.shape[0]):\n",
    "        img, label = read_img(row)        \n",
    "        mask_of_blobs = measure.label(seg_preds[row['img_name']]['mask'])\n",
    "        input_point, input_label = sampler.sample(\n",
    "            mask_of_blobs, seg_preds[row['img_name']]['mask']\n",
    "        )\n",
    "\n",
    "        _start = time.time()\n",
    "        predictor.set_image(img)\n",
    "        sam_logits, iou_scores, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=False,\n",
    "            return_logits=True\n",
    "        )\n",
    "        _end = time.time()\n",
    "        batch_sizes.append(1)\n",
    "        latency_p_batch.append(_end - _start)\n",
    "\n",
    "        logits =  sam_logits[np.argmax(iou_scores)]\n",
    "        binary_mask = logits > 0.0\n",
    "        sam_metrics.step(binary_mask, label)\n",
    "\n",
    "        preds[row['img_name']] = {\n",
    "            'label': label,\n",
    "            'logits': Normalizer.sigmoid(logits).astype(np.float32)\n",
    "        }\n",
    "\n",
    "    sam_metrics = {\n",
    "        **sam_metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "\n",
    "    return sam_metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e389bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse(preds, sam_preds):\n",
    "    fusion_metrics = Metrics()\n",
    "    fusion_preds = {}\n",
    "    for img_name in preds:\n",
    "        fusion = LogitsFusion.apply(\n",
    "            preds[img_name]['logits'],\n",
    "            sam_preds[img_name]['logits'],\n",
    "            method='default')\n",
    "        fusion_preds[img_name] = { 'logits': fusion }\n",
    "        fusion_metrics.step(fusion > TH, sam_preds[img_name]['label'])\n",
    "    \n",
    "    return fusion_metrics.get_results(), fusion_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289190df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(TEST_PATH, TEST_DESCRIPTOR))\n",
    "test_ds = get_dataset(\n",
    "    TEST_PATH,\n",
    "    TEST_DESCRIPTOR,\n",
    "    batch_size=8,\n",
    "    embedding_size=128,\n",
    "    input_size=352)\n",
    "sampler = Sampler(\n",
    "    sampling_step=50,\n",
    "    min_blob_count=10,\n",
    "    mode='grid',\n",
    "    erode_grid='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4681b0-b891-4118-9dbc-fe890ff267c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\UNIPD\\\\SAM/outputs/train/ribs_pvt_small_da1', 'E:\\\\UNIPD\\\\SAM/outputs/train/ribs_cafe_small_da1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\torch\\nn\\functional.py:3782: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "100%|██████████| 7/7 [01:09<00:00,  9.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg. Metrics {'iou': 0.6204378660941883, 'dice': 0.7644125092063282, 'mae': 9.989186664486024, 'f-measure': 0.7488671886674982, 'e-measure': 0.901772510338703, 'fps': 0.8618318118397545, 'latency': 1.160319201800288, 'latency_p_batch': 8.122234412602015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:21<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6360637084708394, 'dice': 0.7768735194441058, 'mae': 9.048432445946698, 'f-measure': 0.7549317705489784, 'e-measure': 0.9046942609827254, 'fps': 0.3515353106050143, 'latency': 2.844664447161616, 'latency_p_batch': 2.844664447161616}\n",
      "Fusion Metrics {'iou': 0.6409931903576157, 'dice': 0.7800227726055444, 'mae': 9.739050742670903, 'f-measure': 0.7668036046733301, 'e-measure': 0.9080097325914086}\n",
      "['E:\\\\UNIPD\\\\SAM/outputs/train/ribs_pvt_da1', 'E:\\\\UNIPD\\\\SAM/outputs/train/ribs_cafe_da1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:56<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg. Metrics {'iou': 0.7461357452480621, 'dice': 0.8538623229118802, 'mae': 6.362168843005437, 'f-measure': 0.8455649588581431, 'e-measure': 0.9447117200033565, 'fps': 1.0827218201380575, 'latency': 0.9235982700270049, 'latency_p_batch': 6.465187890189035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:34<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.7080126979930932, 'dice': 0.8284067812642778, 'mae': 7.338039628605223, 'f-measure': 0.8162090164048258, 'e-measure': 0.9322124411575289, 'fps': 0.3220353704954169, 'latency': 3.1052489621298656, 'latency_p_batch': 3.1052489621298656}\n",
      "Fusion Metrics {'iou': 0.7558047330521354, 'dice': 0.8602138686596486, 'mae': 6.411769390678653, 'f-measure': 0.8540952186698397, 'e-measure': 0.9464095806998338}\n"
     ]
    }
   ],
   "source": [
    "full_preds = []\n",
    "full_sam_preds = []\n",
    "full_fusion_preds = []\n",
    "\n",
    "for i in range(len(MODELS_SETS)):\n",
    "    print(MODELS_SETS[i])\n",
    "    pvt_path = MODELS_SETS[i][0]\n",
    "    cafe_path = MODELS_SETS[i][1]\n",
    "\n",
    "    pvt_config = read_json(os.path.join(pvt_path, 'config.json'))\n",
    "    cafe_config = read_json(os.path.join(cafe_path, 'config.json'))\n",
    "\n",
    "    pvt_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(pvt_path, f\"best_{pvt_config['model_type']}.pth\"),\n",
    "        model_type='pvt')\n",
    "    cafe_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(cafe_path, f\"best_{cafe_config['model_type']}.pth\"),\n",
    "        model_type='cafe')\n",
    "    predictor = predictor_selector(\n",
    "        model_topology='SAMUS',\n",
    "        checkpoint_path=[SAM_WEIGHTS, SAM_MODELS[i]],\n",
    "        model_type='vit_b',\n",
    "        device=DEVICE)\n",
    "    \n",
    "    metrics, preds = eval(test_ds, pvt_model, cafe_model)\n",
    "    print('Seg. Metrics', metrics)\n",
    "    sam_metrics, sam_preds = predict_sam(test_df, predictor, sampler, preds)\n",
    "    print('SAM Metrics', sam_metrics)\n",
    "    fusion_metrics, fusion_preds = fuse(preds, sam_preds)\n",
    "    print('Fusion Metrics', fusion_metrics)\n",
    "\n",
    "    full_preds.append(preds)\n",
    "    full_sam_preds.append(sam_preds)\n",
    "    full_fusion_preds.append(fusion_preds)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08031ba",
   "metadata": {},
   "source": [
    "### Late Ensemble Model Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c435465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "small_da1_preds = full_preds[0]\n",
    "small_da2_preds = full_preds[2]\n",
    "small_fus_preds = {\n",
    "    _k: {\n",
    "        **small_da1_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_preds[_k]['logits'] + small_da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}\n",
    "\n",
    "small_da1_sam_preds = full_sam_preds[0]\n",
    "small_da2_sam_preds = full_sam_preds[2]\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_sam_preds[_k]['logits']\n",
    "                + small_da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in small_da1_sam_preds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c5ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6602243498209209, 'dice': 0.7943975631104319, 'mae': 9.385327547340767, 'f-measure': 0.7836134115752975, 'e-measure': 0.9162794015060504}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, small_da3_preds = fuse(small_fus_preds, small_da1_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9af5765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "da1_preds = full_preds[1]\n",
    "da2_preds = full_preds[3]\n",
    "fus_preds = {\n",
    "    _k: {\n",
    "        **da1_preds[_k],\n",
    "        'logits': (\n",
    "            da1_preds[_k]['logits'] + da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in da1_preds\n",
    "}\n",
    "\n",
    "da1_sam_preds = full_sam_preds[1]\n",
    "da2_sam_preds = full_sam_preds[3]\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            da1_sam_preds[_k]['logits']\n",
    "                + da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aba433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.7686429309002708, 'dice': 0.8684520701086881, 'mae': 5.111098781019195, 'f-measure': 0.8530498327533637, 'e-measure': 0.9467031925486953}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, da3_preds = fuse(fus_preds, fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a053a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samus_path = f'{BASE_PATH}/outputs/train/v1_1_0_small/best_SAMUS.pth'\n",
    "predictor = predictor_selector(\n",
    "    model_topology='SAMUS',\n",
    "    checkpoint_path=[SAM_WEIGHTS, samus_path],\n",
    "    model_type='vit_b',\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e819f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [02:52,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6358890626159537, 'dice': 0.7767126719795495, 'mae': 8.973565291054921, 'f-measure': 0.7539693235311709, 'e-measure': 0.9040754384652328, 'fps': 0.28949259309765196, 'latency': 3.4543198128135835, 'latency_p_batch': 3.4543198128135835}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sam_metrics, small_sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, small_fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c24993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6725449702235992, 'dice': 0.8033278654421616, 'mae': 8.306923982501816, 'f-measure': 0.7861679291655427, 'e-measure': 0.9173022302621321}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ef1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:31<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6378849821719765, 'dice': 0.7782654476356223, 'mae': 9.104353290168705, 'f-measure': 0.7574649069311447, 'e-measure': 0.9068881372491581, 'fps': 0.3277945676507628, 'latency': 3.0506911910310084, 'latency_p_batch': 3.0506911910310084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sam_metrics, sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daa3abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.7705527010067807, 'dice': 0.8697553929427443, 'mae': 5.600976977547058, 'f-measure': 0.8595721182579256, 'e-measure': 0.9488832734141}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(fus_preds, sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c33ec996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMUS 1+2+3\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            da1_sam_preds[_k]['logits'],\n",
    "            da2_sam_preds[_k]['logits'],\n",
    "            sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            small_da1_sam_preds[_k]['logits'],\n",
    "            small_da2_sam_preds[_k]['logits'],\n",
    "            small_sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ed1992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6689124031586137, 'dice': 0.8007171744662946, 'mae': 8.47706125985157, 'f-measure': 0.7840170173855323, 'e-measure': 0.9165229807920677}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
