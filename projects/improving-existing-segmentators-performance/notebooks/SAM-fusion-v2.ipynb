{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7e71cd-bfd2-453a-bc54-253a01a2885b",
   "metadata": {},
   "source": [
    "# <b>Deep Learning:</b>\n",
    "# Improving existing segmentators performance with zero-shot segmentators\n",
    "\n",
    "This Notebook implements the code used in our paper \"Improving existing segmentators performance with zero-shot segmentators\".\n",
    "\n",
    "In our study, we used the predicted segmentation masks from state-of-the-art methods **DeepLabV3+** https://github.com/VainF/DeepLabV3Plus-Pytorch and **PVTv2** https://github.com/whai362/PVT.\n",
    "\n",
    "From these masks, we produce some checkpoints to feed **SAM** (**Segment Anything**, https://github.com/facebookresearch/segment-anything) for *Post-Processing Segmentation Enhancement* or SEEM (**Segment Everything Everywhere All at Once**, https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once) models.\n",
    "\n",
    "The **Segment Anything Model (SAM)** produces high quality object masks from input prompts such as points or boxes, and it can be used to generate masks for all objects in an image. It has been trained on a dataset of 11 million images and 1.1 billion masks, and has strong zero-shot performance on a variety of segmentation tasks.\n",
    "\n",
    "Similarly to SAM, **Segment Everything Everywhere All at Once (SEEM)** allows users to easily segment an image using prompts of different types including visual prompts (points, marks, boxes, scribbles and image segments) and language prompts (text and audio), etc. It can also work with any combinations of prompts or generalize to custom prompts.\n",
    "\n",
    "\n",
    "We devised 4 different methods for producing checkpoints:\n",
    " - A: the pixel whose coordinates are, along each dimension, the average of value of all the mask's pixels coordinate\n",
    " - B: the center of mass of the mask\n",
    " - C: one (or more) pixels drawn (uniformly or not...) randomly inside the mask area\n",
    " - D: pixels drawn from the intersection of a uniform grid of fixed step size and the mask. \"b\" stands for the intersection between the grid and the eroded mask, where the mask is shrinked of 10 pixels.\n",
    "---\n",
    "\n",
    "### In order to run the script, you need to:\n",
    " - set the path to your data folder    (in \"Parameters of the script\" cell)\n",
    " - set the which type of DeepLabV3+ mask to consider (binary or real valued) (in \"Run SAM\" cell)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33681dd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b28288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import cv2                      ## pip install opencv-python\n",
    "import torch                    ## pip install torch\n",
    "import matplotlib.pyplot as plt ## pip install matplotlib\n",
    "import numpy as np              ## pip install numpy\n",
    "import pickle                   ## pip install pickle\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from skimage import measure     ## pip install scikit-image\n",
    "from scipy import ndimage       ## pip install scipy\n",
    "from tqdm import tqdm           ## pip install tqdm\n",
    "###\n",
    "## to download SAM:\n",
    "## git clone git@github.com:facebookresearch/segment-anything.git\n",
    "## cd segment-anything; pip install -e .\n",
    "###\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c816367-81a6-4315-9ccb-96ec3deee17c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### For reproducibility, seed of random generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8172464a-1488-4efe-b203-a0787a38ac5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_PATH = 'c:\\\\Users\\\\gustavo\\\\Documents\\\\SAM\\\\data\\\\test'\n",
    "BASE_OUTPUT_PATH = 'c:\\\\Users\\\\gustavo\\\\Documents\\\\SAM\\\\outputs\\\\test'\n",
    "SAM_SUBMODULES_PATH = 'c:\\\\Users\\\\gustavo\\\\Documents\\\\SAM\\\\pretrained_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Configs\n",
    "VERBOSE = True\n",
    "OVERWRITE_OUTPUTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "SAMPLING_MODE=\"grid\"\n",
    "SAMPLING_STEP=50\n",
    "BORDER_MODE=\"off\"\n",
    "PREDICTION_TH = 0.0\n",
    "\n",
    "# Experiment configuration\n",
    "DEVICE = \"cpu\" # [\"cuda\", \"cpu\"]\n",
    "SOURCE_MASK = \"deeplab\" # [\"oracle\", \"deeplab\", \"pvtv2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "## VIT-H Config\n",
    "SAM_CHECKPOINT = os.path.join(SAM_SUBMODULES_PATH, \"sam_vit_h_4b8939.pth\")\n",
    "MODEL_TYPE = \"default\"\n",
    "\n",
    "## VIT-L Config\n",
    "# SAM_CHECKPOINT = os.path.join(SAM_SUBMODULES_PATH, \"sam_vit_l_0b3195.pth\")\n",
    "# MODEL_TYPE = \"vit_l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASETS = [\n",
    "    # \"CAMO\",\n",
    "    # \"portrait\",\n",
    "    # \"locuste\",\n",
    "    \"ribs\",\n",
    "    # \"SKIN/SKIN_COMPAQ\",\n",
    "    # \"SKIN/SKIN_ECU\",\n",
    "    # \"SKIN/SKIN_HANDGESTURE\",\n",
    "    # \"SKIN/SKIN_MCG\",\n",
    "    # \"SKIN/SKIN_Pratheepan\",\n",
    "    # \"SKIN/SKIN_Schmugge\",\n",
    "    # \"SKIN/SKIN_SFA\",\n",
    "    # \"SKIN/SKIN_uchile\",\n",
    "    # \"SKIN/SKIN_VMD\",\n",
    "    # \"SKIN/SKIN_VT-,\n",
    "    # \"Butterfly/FoldDA1_1\",\n",
    "    # \"Butterfly/FoldDA1_2\",\n",
    "    # \"Butterfly/FoldDA1_3\",\n",
    "    # \"Butterfly/FoldDA1_4\",\n",
    "    # \"COCO_val2017\",\n",
    "    # \"MARS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dd0f8-7e1e-448c-a584-218407de8fa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper function for reading images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "273acfef-c074-4180-a698-af4eeb6472a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_img(path:str) -> np.ndarray:\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def read_bmask(path:str) -> np.ndarray:\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "\n",
    "def read_rmask(path:str) -> np.ndarray:\n",
    "    return cv2.imread(path, cv2.IMREAD_UNCHANGED) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97b748-00f1-4024-b597-8a7fc55f2c90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper functions for displaying points, boxes, and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29bc90d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_mask(mask: np.ndarray, ax, random_color:bool=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords:np.ndarray, labels:np.ndarray, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "    #ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=10, edgecolor='green', linewidth=1.25) # this is if you want the dot\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n",
    "\n",
    "def draw_img(img:np.ndarray, input_point:np.ndarray=None, input_label:np.ndarray=None, \\\n",
    "             mask: np.ndarray=None, title:plt.title = None, plt_show:bool=True):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img)\n",
    "    if mask is not None:\n",
    "        show_mask(mask, plt.gca())\n",
    "    if input_point is not None and input_label is not None:\n",
    "        show_points(input_point, input_label, plt.gca())\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=18)\n",
    "    plt.axis('off')\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "        \n",
    "def draw_results(masks:list, scores:list, gt_mask:np.ndarray, \\\n",
    "                 input_point:np.ndarray, input_label:np.ndarray):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        iou = get_iou(mask, gt_mask)\n",
    "        title = f\"Mask {i+1}, Score: {score:.3f}, IoU: {iou:.3f}\"\n",
    "        draw_img(img, input_point, input_label, mask, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed309f-323d-4899-a693-143245e7e580",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Metrics\n",
    "(between a predicted mask and a Ground Truth mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cc14670-2a29-47a5-9bed-3fc4ecd1c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    eps=np.finfo(np.double).eps\n",
    "\n",
    "    def __init__(self, dataset=None):\n",
    "        self.reset()\n",
    "        self.step        = self.step_common\n",
    "        self.get_iou     = self.get_iou_common\n",
    "        self.get_dice    = self.get_dice_common\n",
    "        self.get_results = self.get_results_common\n",
    "        \n",
    "        if \"SKIN\" in dataset:\n",
    "            self.set_mode_skin()\n",
    "        elif \"Locuste\" in dataset:\n",
    "            self.set_mode_locuste()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tps, self.fps, self.tns, self.fns = 0, 0, 0, 0\n",
    "        self.ious, self.maes, self.dices, self.wfms, self.emes = [], [], [], [], []\n",
    "    \n",
    "    def step_common(self, pred, GT):\n",
    "        iou       = self.get_iou(pred, GT)\n",
    "        dice      = self.get_dice(pred, GT)\n",
    "        mae       = self.compute_mae(pred, GT)\n",
    "        fscore    = self.FbetaMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        e_measure = self.EMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        self.ious.append(iou)\n",
    "        self.dices.append(dice)\n",
    "        self.maes.append(mae)\n",
    "        self.wfms.append(fscore)\n",
    "        self.emes.append(e_measure)\n",
    "    \n",
    "    def step_skin(self, pred, gt):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "        self.tps += np.logical_and(y_true_bool, y_pred_bool).sum()\n",
    "        self.tns += np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        self.fps += np.logical_and(~y_true_bool, y_pred_bool).sum()\n",
    "        self.fns += np.logical_and(y_true_bool, ~y_pred_bool).sum()\n",
    "        \n",
    "        \n",
    "    def step_locuste(self, pred, GT):\n",
    "        iou       = self.get_iou_locuste(pred, GT)\n",
    "        dice      = self.get_dice_locuste(pred.astype(bool), GT.astype(bool))\n",
    "        mae       = self.compute_mae(pred, GT)\n",
    "        e_measure = self.EMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        fscore    = self.FbetaMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        self.ious.append(iou)\n",
    "        self.dices.append(dice)\n",
    "        self.maes.append(mae)\n",
    "        self.wfms.append(fscore)\n",
    "        self.emes.append(e_measure)\n",
    "        \n",
    "    \n",
    "    def get_iou_common(self, pred, gt, beta=1):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "        tp = np.logical_and(y_true_bool, y_pred_bool).sum()\n",
    "        tn = np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        fp = np.logical_and(~y_true_bool, y_pred_bool).sum()\n",
    "        fn = np.logical_and(y_true_bool, ~y_pred_bool).sum()\n",
    "        if tp+fn+fp==0:\n",
    "            if tp==0:\n",
    "                iou=1.0\n",
    "            else:\n",
    "                iou=0.0\n",
    "        else:\n",
    "            iou = tp / (tp + fn + fp)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def get_iou_locuste(self, pred, target, n_classes = 2):\n",
    "        return jaccard_score(target.reshape(-1).astype(bool), pred.reshape(-1).astype(bool))\n",
    "\n",
    "    def get_dice_common(self, pred, gt):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "\n",
    "        tp = np.logical_and( y_true_bool,  y_pred_bool).sum()\n",
    "        tn = np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        fp = np.logical_and(~y_true_bool,  y_pred_bool).sum()\n",
    "        fn = np.logical_and( y_true_bool, ~y_pred_bool).sum()\n",
    "        \n",
    "        if tp+fn+fp==0:\n",
    "            dice=1.0 if tp==0 else 0.0\n",
    "        else:\n",
    "            dice = 2*tp / (2*tp + fn + fp)\n",
    "\n",
    "        return dice\n",
    "\n",
    "    def _calConfusion(self, pred, GT):\n",
    "        TP=np.sum(pred[GT]==1)\n",
    "        FP=np.sum(pred[~GT]==1)\n",
    "        TN=np.sum(pred[~GT]==0)\n",
    "        FN=np.sum(pred[GT]==0)\n",
    "        return TP,FP,TN,FN\n",
    "\n",
    "    def get_dice_locuste(self, pred, GT):\n",
    "        tp, fp, tn, fn = _calConfusion(pred, GT)\n",
    "        return (2.0 * tp) / (2.0 * tp + fp + fn + 1e-7)\n",
    "\n",
    "    def compute_mae(self, pred: np.ndarray, gt: np.ndarray) -> np.ndarray:\n",
    "        mae = np.mean(np.abs(pred - gt))\n",
    "        return mae\n",
    "    \n",
    "    ## F-Measure\n",
    "    def FbetaMeasure(self, pred, GT, beta= math.sqrt(0.3)):\n",
    "        TP,FP,TN,FN=self._calConfusion(pred, GT)\n",
    "        if TP+FN+FN==0:\n",
    "            if TP==0:\n",
    "                Fbeta=1.0\n",
    "            else:\n",
    "                Fbeta=0.0\n",
    "        else:\n",
    "            P=TP/(TP+FP+1e-8) #precision\n",
    "            R=TP/(TP+FN+1e-8) #recall\n",
    "            Fbeta=(beta**2+1)*P*R/((beta**2)*P+R+1e-8)\n",
    "        return Fbeta\n",
    "    \n",
    "    ## E-Measure\n",
    "    def _EnhancedAlignmnetTerm(self, align_Matrix):\n",
    "        enhanced=((align_Matrix+1)**2)/4\n",
    "        return enhanced\n",
    "\n",
    "    def _AlignmentTerm(self, dGT, dpred):\n",
    "        mean_dpred=np.mean(dpred)\n",
    "        mean_dGT=np.mean(dGT)\n",
    "        align_dpred=dpred-mean_dpred\n",
    "        align_dGT=dGT-mean_dGT\n",
    "        align_matrix=2*(align_dGT*align_dpred)/(align_dGT**2+align_dpred**2+self.eps)\n",
    "        return align_matrix\n",
    "\n",
    "    def EMeasure(self, pred, GT):\n",
    "        dGT,dpred=GT.astype(np.float64),pred.astype(np.float64)\n",
    "        if np.sum(GT)==0:#completely black\n",
    "            enhanced_matrix=1-dpred\n",
    "        elif np.sum(~GT)==0:\n",
    "            enhanced_matrix=dpred\n",
    "        else:\n",
    "            align_matrix=self._AlignmentTerm(dGT,dpred)\n",
    "            enhanced_matrix=self._EnhancedAlignmnetTerm(align_matrix)\n",
    "        rows,cols= GT.shape\n",
    "        \n",
    "        # score=np.sum(enhanced_matrix)/(rows*cols-1+self.eps)\n",
    "        score=np.sum(enhanced_matrix)/(rows*cols+self.eps)\n",
    "        return score\n",
    "    \n",
    "    def get_results_common(self) -> (float, float, float, float, float):\n",
    "        return np.array(self.ious).mean(), np.array(self.dices).mean(), np.array(self.maes).mean(), np.array(self.wfms).mean(), np.array(self.emes).mean()\n",
    "\n",
    "    def get_results_skin(self):\n",
    "        iou = self.tps / (self.tps + self.fns + self.fps)\n",
    "        dice = (2.0 * self.tps) / (2.0 * self.tps + self.fps + self.fns + 1e-7)\n",
    "        # for skin dataset, we didn't need the other metrics. TODO: implement\n",
    "        return iou, dice, None, None, None\n",
    "    \n",
    "    def set_mode_locuste(self):\n",
    "        self.step = self.step_locuste\n",
    "        self.get_iou = self.get_iou_locuste\n",
    "        self.get_dice = self.get_dice_locuste\n",
    "    \n",
    "    def set_mode_skin(self):\n",
    "        self.step = self.step_skin\n",
    "        self.get_results = self.get_results_skin\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ea858-a464-46d9-9e9d-294296946908",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions for the sampling of the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e648b45-3339-4e12-9ee8-4ed782671660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Sampler:\n",
    "    verbose = True\n",
    "    sampling_step = None\n",
    "    min_blob_count = None\n",
    "    \n",
    "    def __init__(self, verbose, sampling_step, min_blob_count):\n",
    "        self.verbose        = verbose\n",
    "        self.sampling_step  = sampling_step\n",
    "        self.min_blob_count = min_blob_count\n",
    "    \n",
    "    def sample_pixels(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                x_center, y_center = np.argwhere(mask_bool).sum(0)/count\n",
    "                x_center, y_center = int(x_center) % mask.shape[0], int(y_center) % mask.shape[1]\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? pick the center pixel of image\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [[mask.shape[1]//2, mask.shape[0]//2]], [1]\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample_pixels_center_of_mass(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                x_center, y_center = ndimage.center_of_mass(mask_bool)\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? pick the center pixel of image\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [[mask.shape[1]//2, mask.shape[0]//2]], [1]\n",
    "            print(f\"empty blob -> {input_point}\") if self.verbose else None\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "\n",
    "    def sample_pixels_random(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                indices = np.argwhere(mask_bool)\n",
    "                random_index = np.random.choice(indices.shape[0])\n",
    "                x_center, y_center = indices[random_index]\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? sample a random point\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [ \\\n",
    "                [np.random.randint(0, mask.shape[1]),   \\\n",
    "                 np.random.randint(0, mask.shape[0])]], \\\n",
    "            [1]\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "\n",
    "    def get_grid(self, mask, offset_px_x, offset_px_y):\n",
    "        row = np.zeros(mask.shape, dtype=int)\n",
    "        col = np.zeros(mask.shape, dtype=int)\n",
    "\n",
    "        for i in range(offset_px_y, row.shape[0], self.sampling_step):\n",
    "            row[i, :] = 1\n",
    "        for i in range(offset_px_x, col.shape[1], self.sampling_step):\n",
    "            col[:, i] = 1\n",
    "        res = row & col\n",
    "        return res\n",
    "    \n",
    "    def sample_pixels_grid(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "\n",
    "        # draw a pix for each blob\n",
    "        input_point = []\n",
    "        offset_px_x = 0\n",
    "        offset_px_y = 0\n",
    "        while len(input_point)==0 and offset_px_y < self.sampling_step:\n",
    "            res = self.get_grid(mask, offset_px_x, offset_px_y)\n",
    "\n",
    "            input_point = np.argwhere(res & mask.astype(np.int64))\n",
    "            input_point[:, (0, 1)] = input_point[:, (1, 0)]\n",
    "            \n",
    "            offset_px_x += 1\n",
    "            if offset_px_x>self.sampling_step:\n",
    "                offset_px_x = 0\n",
    "                offset_px_y += 1\n",
    "\n",
    "        # STILL no mask? sample a random point\n",
    "        blob_labels = np.unique(mask_of_blobs)\n",
    "        if len(input_point) <= blob_labels.shape[0]-1:\n",
    "            return self.sample_pixels_random(mask_of_blobs, mask)\n",
    "\n",
    "        input_label = [1 for _ in input_point]\n",
    "        \n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample_pixels_eroded_grid(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        \n",
    "        input_point = []\n",
    "        offset_px_x = 0\n",
    "        offset_px_y = 0\n",
    "        \n",
    "        while len(input_point)==0 and offset_px_y < self.sampling_step:\n",
    "            res = self.get_grid(mask, offset_px_x, offset_px_y)\n",
    "            erode_size = 10\n",
    "        \n",
    "            while True:\n",
    "                # Erode the mask\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_size, erode_size))\n",
    "                eroded_mask = cv2.erode(mask, kernel)\n",
    "\n",
    "                input_point = np.argwhere(res & eroded_mask.astype(np.int64))\n",
    "                input_point[:, (0, 1)] = input_point[:, (1, 0)]\n",
    "\n",
    "                blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "                gt_fl = mask.flatten()\n",
    "\n",
    "                blobs = np.zeros(blob_labels.shape[0], dtype=np.float32)\n",
    "                for i, (bl, bs) in enumerate(zip(blob_labels, blob_sample)):\n",
    "                    mask_bool = (mask_of_blobs==bl)\n",
    "                    count = mask_bool.sum()\n",
    "                    if not (gt_fl[bs]>=1.0 and count>self.min_blob_count): ## it's not a background blob or a false blob\n",
    "                        blobs[i] = -1\n",
    "\n",
    "                for i in range(input_point.shape[0]):\n",
    "                    fl_ip = input_point[i][0]*mask.shape[1] + input_point[i][1]\n",
    "                    idx = mask_of_blobs[input_point[i][1], input_point[i][0]]\n",
    "                    blobs[idx]=1.0\n",
    "                \n",
    "                if not np.any(blobs==0.0) or erode_size==1:\n",
    "                    break\n",
    "                erode_size -= 1\n",
    "            \n",
    "            offset_px_x += 1\n",
    "            if offset_px_x>self.sampling_step:\n",
    "                offset_px_x = 0\n",
    "                offset_px_y += 1\n",
    "            \n",
    "        \n",
    "        input_label = [1 for _ in input_point]\n",
    "\n",
    "        # still no mask? sample a random point\n",
    "        if len(input_point) == 0:\n",
    "            return self.sample_pixels_grid(mask_of_blobs, mask)\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample(self, mode, border_mode, mask_of_blobs: np.ndarray, mask: np.ndarray):\n",
    "        if mode==\"common\": # A\n",
    "            return self.sample_pixels(mask_of_blobs, mask)\n",
    "        elif mode==\"center_of_mass\": # B\n",
    "            return self.sample_pixels_center_of_mass(mask_of_blobs, mask)\n",
    "        elif mode==\"random\": # C\n",
    "            return self.sample_pixels_random(mask_of_blobs, mask)\n",
    "        elif mode==\"grid\": # D\n",
    "            if border_mode==\"on\":\n",
    "                return self.sample_pixels_eroded_grid(mask_of_blobs, mask)\n",
    "            else:\n",
    "                return self.sample_pixels_grid(mask_of_blobs, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce126d-bba7-4ba7-bed7-4bee9e3ee36c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d1e61ba-857e-4283-a825-e7b1fba36993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_complete_output_path(bop, dataset_name, src_msk, model, create=False):\n",
    "    results_dir = os.path.join(bop, dataset_name, src_msk, model)\n",
    "    if create:\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "    return results_dir\n",
    "\n",
    "## get sample points folder path\n",
    "def get_spf_path(\n",
    "    bop, dataset_name,\n",
    "    src_msk, model, s_step,\n",
    "    pnts_smp_mode: str='', \n",
    "    border_mode: str='on',\n",
    "    create=False):\n",
    "    folder_name = (\n",
    "        pnts_smp_mode \n",
    "            + ((\"_\" + str(s_step)) if pnts_smp_mode==\"grid\" else \"\")\n",
    "            + (\"_bm\" if border_mode==\"on\" and pnts_smp_mode==\"grid\" else \"\")\n",
    "    )\n",
    "    sampled_points_folder = os.path.join(\n",
    "        bop, \"sampled_points_final\", dataset_name, src_msk, model, folder_name\n",
    "    )\n",
    "    if create:\n",
    "        os.makedirs(sampled_points_folder, exist_ok=True)\n",
    "    return sampled_points_folder\n",
    "\n",
    "\n",
    "def get_min_blob_number_based_on_dataset(dataset):\n",
    "    return 20 if dataset==\"portrait\" else 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7c324b4-e257-489b-a14c-04612588f5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadpaths(dataset_path, dataset_name, segmentator_name):\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(dataset_path, dataset_name)):\n",
    "        print(\"ERROR. provided dataset does not exist!\")\n",
    "        return None\n",
    "    \n",
    "    orig_images_folder = os.path.join(dataset_path, dataset_name, \"imgs\")\n",
    "    gt_folder          = os.path.join(dataset_path, dataset_name, \"gt\")\n",
    "    segmentator_folder = os.path.join(\n",
    "        dataset_path, dataset_name, \"segmentator_\" + segmentator_name\n",
    "    )\n",
    "    \n",
    "    ## Load input images ##\n",
    "    test_imgs = glob.glob(os.path.join(orig_images_folder, '*'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in test_imgs]\n",
    "    test_imgs = [\n",
    "        test_imgs[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])\n",
    "    ]\n",
    "    \n",
    "    ## Load GT masks ##\n",
    "    gt_masks = glob.glob(os.path.join(gt_folder, '*'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in gt_masks]\n",
    "    gt_masks = [\n",
    "        gt_masks[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])\n",
    "    ]\n",
    "    \n",
    "    print(os.path.join(segmentator_folder, '*.bmp'))\n",
    "\n",
    "    ## Load DeepLabV3+ produced binary masks ##\n",
    "    segmentator_bmasks = glob.glob(os.path.join(segmentator_folder, '*.bmp'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in segmentator_bmasks]\n",
    "    segmentator_bmasks = [\n",
    "        segmentator_bmasks[i]\n",
    "        for i in sorted(range(len(bn)), key=lambda k: bn[k])\n",
    "    ]\n",
    "\n",
    "    ## Load DeepLabV3+ produced 3D masks ##\n",
    "    segmentator_rmasks = glob.glob(os.path.join(segmentator_folder, '*.png'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in segmentator_rmasks]\n",
    "    segmentator_rmasks = [segmentator_rmasks[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])]\n",
    "        \n",
    "    return [test_imgs, gt_masks, segmentator_bmasks, segmentator_rmasks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa58c87-c503-4019-ae47-2639a514627d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765e952",
   "metadata": {
    "tags": []
   },
   "source": [
    "Predict with `SamPredictor.predict`. The model returns\n",
    " - masks  (`masks.shape  # (number_of_masks) x H x W) ` )\n",
    " - quality predictions for those masks\n",
    " - low resolution mask logits that can be passed to the next iteration of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0e938",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `predict()` function accepts three parameters (among many):\n",
    "\n",
    " - `point_coords`: an np.ndarray of 2D pixels that will provide SAM the checkpoints/seeds of the object to segment\n",
    " - `point_labels`: is the corresponding pixel a pixel belonging to the object (1) or not (0) ?\n",
    "\n",
    " - With `multimask_output=True` (the default setting), SAM outputs 3 masks, where `scores` gives the model's own estimation of the quality of these masks. This setting is intended for ambiguous input prompts, and helps the model disambiguate different objects consistent with the prompt. When `False`, it will return a single mask. For ambiguous prompts such as a single point, it is recommended to use `multimask_output=True` even if only a single mask is desired; the best single mask can be chosen by picking the one with the highest score returned in `scores`. This will often result in a better mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_paths(dataset_name: str, source_mask: str):\n",
    "     paths = loadpaths(DATASET_PATH, dataset_name, source_mask)\n",
    "     lens = list(map(lambda i: len(i), paths))\n",
    "     print('paths', paths)\n",
    "\n",
    "     # if there are no 3D liogits, repeat the 2D ones for consistency purposes\n",
    "     if lens[3] == 0:\n",
    "          paths[3] = paths[2]\n",
    "          lens[3] = lens[2]\n",
    "\n",
    "     # check if the images and the ground truths have the same quantity\n",
    "     img_has_gt_len = lens[0] == lens[1]\n",
    "     # check if either of the masks (2D or 3D logits) matches with the len of\n",
    "     # the images\n",
    "     mask_has_img_len = (\n",
    "        (lens[0] == lens[2] == lens[3])\n",
    "          or (lens[0] == lens[2])\n",
    "          or (lens[0] == lens[3])\n",
    "     )\n",
    "     assert img_has_gt_len and mask_has_img_len, f\"unbalanced datasets! {lens}\"\n",
    "     del lens\n",
    "\n",
    "     return list(zip(*paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs_from_paths(paths: tuple) -> tuple:\n",
    "    # Get paths\n",
    "    img_path, gt_mask_path, src_bmask_path, src_rmask_path = paths\n",
    "    print(\"img_path          :\", img_path)\n",
    "    print(\"gt_mask_path      :\", gt_mask_path)\n",
    "    print(\"dplabv3_bmask_path:\", src_bmask_path)\n",
    "    print(\"dplabv3_rmask_path:\", src_rmask_path)\n",
    "    \n",
    "    # Load images from disk using paths\n",
    "    return (\n",
    "        read_img(img_path),\n",
    "        read_bmask(gt_mask_path),\n",
    "        read_bmask(src_bmask_path),\n",
    "        read_rmask(src_rmask_path)\n",
    "    )\n",
    "\n",
    "def img_shape_matches(loaded_images: tuple, source_mask: str = 'oracle'):\n",
    "    img, gt_mask, src_bmask, src_rmask = loaded_images\n",
    "    img_matches_gt = img.shape[:2] == gt_mask.shape\n",
    "\n",
    "    if source_mask==\"oracle\":\n",
    "        return img_matches_gt\n",
    "            \n",
    "    return img_matches_gt and (src_bmask.shape == src_rmask.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34bde0a0-6c4f-4799-af95-eb50ab212758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform(\n",
    "        predictor,\n",
    "        dataset_name: str,\n",
    "        model_type: str = 'defaut',\n",
    "        source_mask: str = 'deeplab',\n",
    "        points_sampling_mode: str = 'grid',\n",
    "        sampling_step: int = 50,\n",
    "        border_mode: str = 'on',\n",
    "        predict_threshold: float = 0.0):\n",
    "    is_model_cuda = next(predictor.model.parameters()).is_cuda\n",
    "    data_paths = get_data_paths(dataset_name, source_mask)\n",
    "    data_len = len(data_paths)\n",
    "    if VERBOSE: print(\"len of files:\", data_len)\n",
    "\n",
    "    # Get the Sampler (used for generating the prompts)\n",
    "    sampler = Sampler(\n",
    "        VERBOSE,\n",
    "        sampling_step,\n",
    "        get_min_blob_number_based_on_dataset(dataset_name))\n",
    "\n",
    "    results_dir = get_complete_output_path(\n",
    "        BASE_OUTPUT_PATH,\n",
    "        dataset_name,\n",
    "        source_mask,\n",
    "        model_type,\n",
    "        create=True)\n",
    "    sampled_points_folder = get_spf_path(\n",
    "        BASE_OUTPUT_PATH,\n",
    "        dataset_name,\n",
    "        source_mask,\n",
    "        model_type,\n",
    "        sampling_step,\n",
    "        pnts_smp_mode=points_sampling_mode,\n",
    "        border_mode=border_mode,\n",
    "        create=True)\n",
    "    print(\"results will be saved at for results_dir\", results_dir)\n",
    "    \n",
    "    for idx, paths in tqdm(enumerate(data_paths), total=data_len):\n",
    "        if VERBOSE: print(f\" - img idx {str(idx+1).zfill(6)}/{data_len}:\")\n",
    "    \n",
    "        # Load images from disk using paths\n",
    "        loaded_images = read_imgs_from_paths(paths)\n",
    "\n",
    "        if not img_shape_matches(loaded_images, source_mask=source_mask):\n",
    "            print('A mismatch between image shapes has been found!')\n",
    "            continue\n",
    "\n",
    "        # Output paths to the resulting binary mask and logits\n",
    "        basename = os.path.basename(paths[0])\n",
    "        basename = basename[:basename.rfind(\".\") + 1]\n",
    "        out_mask_path = os.path.join(results_dir, basename + \"npy\")\n",
    "        out_logits_path = os.path.join(results_dir, 'low_'+ basename + \"npy\")\n",
    "        out_mask_best_path = os.path.join(results_dir, basename + \"jpg\")\n",
    "        if (not OVERWRITE_OUTPUTS\n",
    "                and os.path.exists(out_mask_path)\n",
    "                and os.path.exists(out_mask_best_path)\n",
    "                and os.path.exists(out_logits_path)):\n",
    "            print(f'\"{out_mask_path}\" already exists, skipping file.')\n",
    "            continue\n",
    "\n",
    "        img, gt_mask, src_bmask, _ = loaded_images\n",
    "\n",
    "        mask_to_sample = gt_mask if source_mask == \"oracle\" else src_bmask\n",
    "        # Count the number of distinct labels\n",
    "        #  -> it corresponds to the # of blobs\n",
    "        mask_of_blobs = measure.label(mask_to_sample)\n",
    "        \n",
    "        # Sample the checkpoints (at least one for blob)\n",
    "        unique_blobs = np.unique(mask_of_blobs)\n",
    "        num_blobs = unique_blobs.shape[0]\n",
    "        bin_path = os.path.join(\n",
    "            sampled_points_folder, os.path.basename(paths[1])[:-4] + \".bin_\"\n",
    "        )\n",
    "        if num_blobs==1 and 0 in unique_blobs:\n",
    "            input_point, input_label = np.array([]), np.array([])\n",
    "            input_point.tofile(bin_path)\n",
    "            \n",
    "            binary_mask = mask_to_sample\n",
    "            masks=[binary_mask]\n",
    "            best_score_idx=0\n",
    "        else:\n",
    "            input_point, input_label = sampler.sample(\n",
    "                points_sampling_mode,\n",
    "                border_mode,\n",
    "                mask_of_blobs,\n",
    "                mask_to_sample)\n",
    "            input_point.tofile(bin_path)\n",
    "            predictor.set_image(img)\n",
    "            masks, scores, _ = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=True,\n",
    "                return_logits=True\n",
    "            )\n",
    "\n",
    "            if is_model_cuda:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            best_score_idx = np.argmax(scores)\n",
    "            binary_mask = masks[best_score_idx] > predict_threshold\n",
    "        \n",
    "        # save the outputs\n",
    "        cv2.imwrite(out_mask_best_path, masks[best_score_idx] * 255)\n",
    "        np.save(out_mask_path, masks)\n",
    "        np.save(out_logits_path, masks[best_score_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_all(dataset_name, predictor, model_type, source_mask, ):\n",
    "    with torch.no_grad():\n",
    "        perform(\n",
    "            predictor,\n",
    "            dataset_name,\n",
    "            model_type=model_type,\n",
    "            source_mask=source_mask,\n",
    "            points_sampling_mode=SAMPLING_MODE,\n",
    "            sampling_step=SAMPLING_STEP,\n",
    "            border_mode=BORDER_MODE,\n",
    "            predict_threshold=PREDICTION_TH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de05606-e970-45cd-9aa7-3e440226a16e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model init\n",
    "print(f\"creating sam {MODEL_TYPE} and moving it to device\")\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT)\n",
    "sam.to(device=DEVICE)\n",
    "print(\"creating predictor\")\n",
    "predictor = SamPredictor(sam)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54a09c-5dcb-4f97-886e-7981249eb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment on the datasets\n",
    "for dataset in DATASETS:\n",
    "    perform_all(dataset, predictor, MODEL_TYPE, SOURCE_MASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89962ddf-d697-4266-a6be-fd9f4299e62e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics_obj: Metrics):\n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics_obj.get_results()\n",
    "    print('Total number of objects: ', len(metrics_obj.ious))    \n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    print(f\"average mae      : {mae_avg*100:5.2f}\")\n",
    "    print(f\"average f-measure: {wfm_avg*100:5.2f}\")\n",
    "    print(f\"average e-measure: {eme_avg*100:5.2f}\")\n",
    "    print()\n",
    "\n",
    "    return {\n",
    "        'iou': iou_avg,\n",
    "        'dice': dice_avg,\n",
    "        'mae': mae_avg,\n",
    "        'f-measure': wfm_avg,\n",
    "        'e-measure': eme_avg,\n",
    "    }\n",
    "\n",
    "def dump_metrics(\n",
    "        database_name: str,\n",
    "        in_met: dict,\n",
    "        pred_met: dict,\n",
    "        fus_met: dict):\n",
    "    indexes = ['iou', 'dice', 'mae', 'f-measure', 'e-measure']\n",
    "    out_path = os.path.join(BASE_OUTPUT_PATH, database_name, 'metrics.csv')\n",
    "    pd.DataFrame({\n",
    "        'input': [in_met[idx] for idx in indexes],\n",
    "        'pred': [pred_met[idx] for idx in indexes],\n",
    "        'fusion': [fus_met[idx] for idx in indexes]\n",
    "    }, index=indexes).to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_stats(out_path: str, file_names: list, metrics: Metrics):\n",
    "    pd.DataFrame({\n",
    "        'filenames': file_names,\n",
    "        'iou': metrics.ious,\n",
    "        'dice': metrics.dices,\n",
    "        'mae': metrics.maes,\n",
    "        'f-measure': metrics.wfms,\n",
    "        'e-measure': metrics.emes\n",
    "    }).to_csv(out_path)\n",
    "\n",
    "def dump_input_stats(database_name: str, file_names: list, metrics: Metrics):\n",
    "    dump_stats(\n",
    "        os.path.join(BASE_OUTPUT_PATH, database_name, 'input_stats.csv'),\n",
    "        file_names, metrics\n",
    "    )\n",
    "\n",
    "def dump_pred_stats(database_name: str, file_names: list, metrics: Metrics):\n",
    "    dump_stats(\n",
    "        os.path.join(BASE_OUTPUT_PATH, database_name, 'pred_stats.csv'),\n",
    "        file_names, metrics\n",
    "    )\n",
    "\n",
    "def dump_fusion_stats(database_name: str, file_names: list, metrics: Metrics):\n",
    "    dump_stats(\n",
    "        os.path.join(BASE_OUTPUT_PATH, database_name, 'fusion_stats.csv'),\n",
    "        file_names, metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionRules:\n",
    "    @staticmethod\n",
    "    def apply_default(b_mask, pred_mask):\n",
    "        return (\n",
    "            (abs(255 - pred_mask.astype('uint8')) + 2 * b_mask) / 3\n",
    "        ).astype(np.uint8) < 128\n",
    "\n",
    "    @staticmethod\n",
    "    def __apply_kitter(b_mask, pred_mask, numpy_op):\n",
    "        bin_mask = b_mask.astype('float32')\n",
    "        prob_mask = torch.sigmoid(torch.from_numpy(pred_mask[1, :, :])).numpy()\n",
    "\n",
    "        return numpy_op([bin_mask, prob_mask], axis=0)\n",
    "\n",
    "    @classmethod\n",
    "    def apply_sum(cls, b_mask, pred_mask):\n",
    "        return cls.__apply_kitter(b_mask, pred_mask, np.sum)\n",
    "\n",
    "    @classmethod\n",
    "    def apply_min(cls, b_mask, pred_mask):\n",
    "        return cls.__apply_kitter(b_mask, pred_mask, np.min)\n",
    "\n",
    "    @classmethod\n",
    "    def apply_max(cls, b_mask, pred_mask):\n",
    "        return cls.__apply_kitter(b_mask, pred_mask, np.max)\n",
    "\n",
    "    @classmethod\n",
    "    def apply_avg(cls, b_mask, pred_mask):\n",
    "        return cls.__apply_kitter(b_mask, pred_mask, np.average)\n",
    "\n",
    "    @classmethod\n",
    "    def apply_median(cls, b_mask, pred_mask):\n",
    "        return cls.__apply_kitter(b_mask, pred_mask, np.median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    input_metrics = Metrics(dataset)\n",
    "    sam_metrics = Metrics(dataset)\n",
    "    fusion_metrics = Metrics(dataset)\n",
    "\n",
    "    pred_path = os.path.join(\n",
    "        BASE_OUTPUT_PATH, dataset, SOURCE_MASK, MODEL_TYPE\n",
    "    )\n",
    "    paths = get_data_paths(dataset, SOURCE_MASK)\n",
    "\n",
    "    basenames = []\n",
    "    mask_difference = []\n",
    "    print(\"Processing data in directory: \", pred_path, flush=True)\n",
    "    for idx, img_paths in tqdm(enumerate(paths), total=len(paths)):\n",
    "        img_path, gt_mask_path, bmask_path, rmask_path = img_paths\n",
    "\n",
    "        # get the input images and groundtruth\n",
    "        gt_mask = read_bmask(gt_mask_path).astype(np.float32)\n",
    "        b_mask = read_bmask(bmask_path).astype(np.float32)\n",
    "        del gt_mask_path, bmask_path\n",
    "\n",
    "        # get the prediction input\n",
    "        basename = os.path.basename(img_path)\n",
    "        basenames.append(basename)\n",
    "        pred_mask_fname = basename[:basename.rfind(\".\")+1] + \"jpg\"\n",
    "        pred_mask_path = os.path.join(pred_path, pred_mask_fname)\n",
    "        logit_path = pred_mask_path[:-3] + 'npy'\n",
    "\n",
    "        pred_mask = read_bmask(pred_mask_path).astype(np.float32)\n",
    "        del img_path, pred_mask_fname, pred_mask_path\n",
    "\n",
    "        mask_difference.append((gt_mask - b_mask).sum())\n",
    "\n",
    "        # get the fusion mask\n",
    "        logit_mask = None #np.load(logit_path)\n",
    "        r_mask = read_rmask(rmask_path).astype(np.float32)\n",
    "        fusion_mask = FusionRules.apply_default(gt_mask, r_mask)\n",
    "        del logit_path, logit_mask\n",
    "\n",
    "        input_metrics.step(b_mask, gt_mask)\n",
    "        sam_metrics.step(pred_mask > PREDICTION_TH, gt_mask)\n",
    "        fusion_metrics.step(fusion_mask, gt_mask)\n",
    "        del gt_mask, b_mask, pred_mask\n",
    "\n",
    "    print(f'Results from {SOURCE_MASK}')\n",
    "    in_met_dict = print_metrics(input_metrics)\n",
    "    dump_input_stats(dataset, basenames, input_metrics)\n",
    "    del input_metrics\n",
    "\n",
    "    print(f'Results from SAM')\n",
    "    sam_met_dict = print_metrics(sam_metrics)\n",
    "    dump_pred_stats(dataset, basenames, sam_metrics)\n",
    "    del sam_metrics\n",
    "    \n",
    "    print(f'Results from Fusion')\n",
    "    fus_met_dict = print_metrics(fusion_metrics)\n",
    "    dump_fusion_stats(dataset, basenames, fusion_metrics)\n",
    "    del fusion_metrics\n",
    "\n",
    "    dump_metrics(\n",
    "        dataset, in_met_dict, sam_met_dict, fus_met_dict\n",
    "    )\n",
    "\n",
    "    print(max(mask_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('/media/zanoni/SSDZ/SAM/outputs/ribs/deeplab/default/low_799.npy')\n",
    "print(x.shape, x.max(), x.min())\n",
    "sb.heatmap(torch.sigmoid(torch.from_numpy(x[1, :, :])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4607e-19e5-4c60-90bb-5cb667751b71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## evaluate fusion performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d986cf-e822-4550-913b-f81cc8cc2017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"default\"\n",
    "#### TODO: oracle still suffers from: no folder \"segmentator_oracle\"...need to fix it!\n",
    "source_mask = \"deeplab\" # \"deeplab\", \"pvtv2\", \"oracle\", \"sota\" # ...it depends!\n",
    "points_sampling_mode = \"D\"\n",
    "sampling_step = 50\n",
    "border_mode = \"off\"\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    pred_path = os.path.join(BASE_OUTPUT_PATH, dataset, source_mask, model_type)\n",
    "    print(pred_path)\n",
    "    os.makedirs(pred_path, exist_ok=True)\n",
    "\n",
    "    metrics, source_mask_metrics, metrics_fusion = Metrics(dataset), Metrics(dataset), Metrics(dataset)\n",
    "    test_imgs, gt_masks, src_bmasks, src_rmasks = loadpaths(DATASET_PATH, dataset, source_mask)\n",
    "    toiterate = zip(test_imgs, gt_masks, src_bmasks, src_rmasks)\n",
    "    \n",
    "    for idx, paths in tqdm(enumerate(toiterate), total=len(gt_masks)):\n",
    "        if VERBOSE:\n",
    "            print(f\" - img idx {str(idx+1).zfill(6)}/{len(test_imgs)}:\")\n",
    "\n",
    "        # Get paths\n",
    "        img_path, gt_mask_path, src_bmask_path, src_rmask_path = paths\n",
    "    \n",
    "        basename = os.path.basename(img_path)\n",
    "        in_mask_path = pred_path + \"/\" + basename[:basename.rfind(\".\")+1]+\"jpg\"\n",
    "        \n",
    "        # Load images from disk using paths\n",
    "        gt_mask   = read_bmask(gt_mask_path).astype(np.float32)\n",
    "        src_bmask = read_bmask(src_bmask_path).astype(np.float32)\n",
    "        src_rmask = read_bmask(src_rmask_path).astype(np.float64) * 255\n",
    "        assert gt_mask.shape == src_bmask.shape \\\n",
    "                == src_rmask.shape[:2], \"Error: shape mismatch\"\n",
    "        \n",
    "        img = cv2.imread(in_mask_path)[:, :, 0]\n",
    "        binary_mask = img > 0\n",
    "        \n",
    "        metrics.step(binary_mask, gt_mask)\n",
    "        source_mask_metrics.step(src_bmask, gt_mask)\n",
    "        \n",
    "        pred_mask = abs(255 - img.astype('uint8'))\n",
    "        pred_mask = ((pred_mask + 2*src_rmask)/3).astype(np.uint8) < 128\n",
    "        metrics_fusion.step(pred_mask, gt_mask)\n",
    "        \n",
    "        # break\n",
    "\n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics.get_results()\n",
    "    print(len(metrics.ious))\n",
    "    print()\n",
    "    \n",
    "    print(\"SAM alone metrics:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    # print(f\"average mae      : {mae_avg*100:5.2f}\")\n",
    "    # print(f\"average f-measure: {wfm_avg*100:5.2f}\")\n",
    "    # print(f\"average e-measure: {eme_avg*100:5.2f}\")\n",
    "\n",
    "    print()\n",
    "    \n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = source_mask_metrics.get_results()\n",
    "    print(f\"segmentator_{source_mask} metrics:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    # print(f\"average mae      : {mae_avg*100:5.2f}\")\n",
    "    # print(f\"average f-measure: {wfm_avg*100:5.2f}\")\n",
    "    # print(f\"average e-measure: {eme_avg*100:5.2f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics_fusion.get_results()\n",
    "    print(\"SAM-fusion performance:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    # print(f\"average mae      : {mae_avg*100:5.2f}\")\n",
    "    # print(f\"average f-measure: {wfm_avg*100:5.2f}\")\n",
    "    # print(f\"average e-measure: {eme_avg*100:5.2f}\")\n",
    "    \n",
    "    with open(f'{pred_path}/metrics.pickle', 'wb') as handle:\n",
    "        pickle.dump(metrics, handle)\n",
    "    with open(f'{pred_path}/source_mask_metrics.pickle', 'wb') as handle:\n",
    "        pickle.dump(source_mask_metrics, handle)\n",
    "    with open(f'{pred_path}/metrics_fusion_{source_mask}.pickle', 'wb') as handle:\n",
    "        pickle.dump(metrics_fusion, handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3656440-6cc2-471a-974b-6bf73c3189ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, source_mask_metrics = analyze(predictor, model_type, source_mask, dataset, \"D\", 50, \"off\")\n",
    "# iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics.get_results()\n",
    "iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = source_mask_metrics.get_results()\n",
    "print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "print(f\"average mae      : {mae_avg*100:5.2f}\")\n",
    "print(f\"average f-measure: {wfm_avg*100:5.2f}\")\n",
    "print(f\"average e-measure: {eme_avg*100:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d502c5d-6dfd-418c-9eb7-012adad144b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VISUALIZE IMAGES (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cf5e9-0d4f-45c3-ae37-a9866f99997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_path = \"/home/fusaro/segment-anything\"\n",
    "def perform(predictor, model_type, source_mask, dataset, points_sampling_mode, sampling_step, border_mode):\n",
    "    global verbose\n",
    "    min_blob_count = 20 if dataset==\"portrait\" else 10\n",
    "    test_folder, gt_folder, dplabv3_folder, pvtv2_folder,\\\n",
    "              img_ext = loadinfo(dataset, dataset_path)\n",
    "    \n",
    "    if \"COCO\" in dataset:\n",
    "        test_imgs, gt_masks, src_bmasks, src_rmasks = loadpaths_COCO(test_folder, gt_folder, dplabv3_folder)\n",
    "    else:\n",
    "        if source_mask==\"pvtv2\":\n",
    "            test_imgs, gt_masks, src_bmasks, src_rmasks = loadpaths(test_folder, gt_folder, pvtv2_folder)\n",
    "        else:\n",
    "            test_imgs, gt_masks, src_bmasks, src_rmasks = loadpaths(test_folder, gt_folder, dplabv3_folder)\n",
    "\n",
    "        assert len(test_imgs) == len(gt_masks) == len(src_bmasks) == len(src_rmasks),\\\n",
    "                  f\"unbalanced datasets! {len(test_imgs)} {len(gt_masks)} {len(src_rmasks)}\"\n",
    "    \n",
    "    toiterate = zip(test_imgs, gt_masks, src_bmasks, src_rmasks)\n",
    "\n",
    "    print(\"len of files:\", len(test_imgs)) if VERBOSE else None\n",
    "    \n",
    "    # metrics = Metrics()\n",
    "    # source_mask_metrics = Metrics()\n",
    "    \n",
    "    results_dir = \"/home/fusaro/segment-anything/SKIN_out/\" + dataset + \"/\" + source_mask + \"/\" + model_type\n",
    "    # os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"processing for results_dir\", results_dir)\n",
    "    \n",
    "    # sampled_points_folder = os.path.join(\"/home/fusaro/segment-anything/SKIN_out/sampled_points_final\", dataset, source_mask, model_type, \\\n",
    "    #                             points_sampling_mode + ((\"_\" + str(sampling_step)) if points_sampling_mode==\"D\" else \"\") \\\n",
    "    #                             + (\"_bm\" if border_mode==\"on\" and points_sampling_mode==\"D\" else \"\"))\n",
    "\n",
    "    sampled_points_folder = os.path.join(dataset_path, \"sampled_points_final\", dataset, source_mask, \\\n",
    "                                points_sampling_mode + ((\"_\" + str(sampling_step)) if points_sampling_mode==\"D\" else \"\") \\\n",
    "                                + (\"_bm\" if border_mode==\"on\" and points_sampling_mode==\"D\" else \"\"))\n",
    "    \n",
    "    # os.makedirs(sampled_points_folder, exist_ok=True)\n",
    "    # verbose=True\n",
    "    for idx, paths in tqdm(enumerate(toiterate), total=len(test_imgs)):\n",
    "        if idx < 46:\n",
    "            continue\n",
    "        \n",
    "        print(f\" - img idx {str(idx+1).zfill(6)}/{len(test_imgs)}:\") if VERBOSE else None\n",
    "        \n",
    "        img_path, gt_mask_path, src_bmask_path, src_rmask_path = paths\n",
    "        print(\"img_path          :\", img_path)\n",
    "        print(\"gt_mask_path      :\", gt_mask_path)\n",
    "        print(\"dplabv3_bmask_path:\", src_bmask_path)\n",
    "        print(\"dplabv3_rmask_path:\", src_rmask_path)\n",
    "\n",
    "        # Load images from disk using paths\n",
    "        img       = read_img(img_path)\n",
    "        gt_mask   = read_bmask(gt_mask_path)\n",
    "        src_bmask = 1.0 - read_bmask(src_rmask_path)\n",
    "        src_rmask = read_rmask(src_rmask_path).astype(np.float64)\n",
    "        \n",
    "        input_point = np.fromfile(os.path.join(sampled_points_folder,os.path.basename(gt_mask_path)[:-4]+\".bin\"), dtype=np.int64).reshape(-1, 2)\n",
    "        print(input_point)\n",
    "        # if input_point.shape[0]<2:\n",
    "        #     continue\n",
    "#         print(os.path.join(sampled_points_folder,os.path.basename(gt_mask_path)[:-4]+\".bin_\"))\n",
    "#         print(input_point.shape)\n",
    "        \n",
    "#         # input_label = [1 for _ in input_point]\n",
    "        \n",
    "#         # TO VISUALIZE computed mask, show the superposition with the original image\n",
    "#         # and SAM's predicted score and IoU wrt Ground Truth mask\n",
    "#         color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "        \n",
    "        color = np.array([1.0, 0, 0.80, 0.6])\n",
    "        \n",
    "        \n",
    "#         plt.clf()\n",
    "#         fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 20))\n",
    "#         axes[0].imshow(img)\n",
    "#         axes[0].set_title('img', fontsize = 16)\n",
    "#         if input_point.shape[0]>0:\n",
    "#             print(\"true\")\n",
    "#             axes[0].scatter([input_point[:, 0]], [input_point[:, 1]], color='green', marker='*', s=100, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "        \n",
    "#         axes[1].imshow(img)\n",
    "#         h, w = gt_mask.shape[-2:]\n",
    "#         mask_image = gt_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         axes[1].set_title('GT', fontsize = 16)\n",
    "#         axes[1].imshow(mask_image)\n",
    "        \n",
    "#         axes[2].imshow(img)\n",
    "#         h, w = pred_mask.shape[-2:]\n",
    "#         mask_image = pred_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         axes[2].set_title('sota-dlv3', fontsize = 16)\n",
    "#         axes[2].imshow(mask_image)\n",
    "        \n",
    "#         axes[3].imshow(img)\n",
    "#         h, w = src_bmask.shape[-2:]\n",
    "#         mask_image = src_bmask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         axes[3].set_title('dlv3', fontsize = 16)\n",
    "#         axes[3].scatter([input_point[:, 0]], [input_point[:, 1]], color='green', marker='*', s=100, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "#         axes[3].imshow(mask_image)\n",
    "        \n",
    "#         axes[4].imshow(img)\n",
    "#         h, w = fusion_mask.shape[-2:]\n",
    "#         mask_image = fusion_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         axes[4].set_title('sota-fusion', fontsize = 16)\n",
    "#         axes[4].imshow(mask_image)\n",
    "\n",
    "#         fig.tight_layout()\n",
    "        \n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.clf()\n",
    "#         plt.imshow(img)\n",
    "#         plt.scatter([input_point[:, 0]], [input_point[:, 1]], color='blue', marker='*', s=80, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(f'imgs/new_{idx}_img.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "#         plt.clf()\n",
    "#         # color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "#         h, w = gt_mask.shape[-2:]\n",
    "#         mask_image = gt_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         plt.imshow(img)\n",
    "#         plt.imshow(mask_image)\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(f'imgs/new_{idx}_gt.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "#         plt.clf()\n",
    "#         plt.imshow(img)\n",
    "#         h, w = pred_mask.shape[-2:]\n",
    "#         mask_image = pred_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         plt.imshow(mask_image)\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(f'imgs/new_{idx}_samdlv3.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "#         plt.clf()\n",
    "#         plt.imshow(img)\n",
    "#         h, w = fusion_mask.shape[-2:]\n",
    "#         mask_image = fusion_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#         plt.imshow(mask_image)\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(f'imgs/new_{idx}_samfusion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.imshow(img)\n",
    "        h, w = src_bmask.shape[-2:]\n",
    "        mask_image = src_bmask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        ax.scatter([input_point[:, 0]], [input_point[:, 1]], color='green', marker='*', s=100, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "        ax.imshow(mask_image)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        plt.clf()\n",
    "        plt.imshow(img)\n",
    "        h, w = src_bmask.shape[-2:]\n",
    "        mask_image = src_bmask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        plt.scatter([input_point[:, 0]], [input_point[:, 1]], color='blue', marker='*', s=30, edgecolor='white', linewidth=0.5) # this is if you want the star\n",
    "        plt.imshow(mask_image)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'imgs/{idx}_dlv3_d50.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        if idx>24:\n",
    "            break\n",
    "\n",
    "# perform(None, \"default\", \"deeplab\", \"COCO_animal\", \"D\", 50, \"off\")\n",
    "perform(None, \"default\", \"deeplab\", \"portrait\", \"D\", 50, \"off\")\n",
    "# perform(None, \"default\", \"deeplab\", \"sota_FoldDA1_3\", \"D\", 50, \"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
