{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a56376-5973-44a0-a64b-cf37030cf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:384: UserWarning: Overwriting pvt_v2_b0 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b0. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b0(PyramidVisionTransformerImpr):\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:394: UserWarning: Overwriting pvt_v2_b1 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b1. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b1(PyramidVisionTransformerImpr):\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:402: UserWarning: Overwriting pvt_v2_b2 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b2. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b2(PyramidVisionTransformerImpr):\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:410: UserWarning: Overwriting pvt_v2_b3 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b3(PyramidVisionTransformerImpr):\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:418: UserWarning: Overwriting pvt_v2_b4 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b4(PyramidVisionTransformerImpr):\n",
      "c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\unipd_sam_med\\models\\cafe_net\\pvtv2.py:427: UserWarning: Overwriting pvt_v2_b5 in registry with unipd_sam_med.models.cafe_net.pvtv2.pvt_v2_b5. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  class pvt_v2_b5(PyramidVisionTransformerImpr):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import measure\n",
    "\n",
    "from seg_lib.dataloaders.sam_dataset import SamGeneralDataset\n",
    "from seg_lib.eval.metrics import Metrics\n",
    "from seg_lib.eval.fusion import LogitsFusion\n",
    "from seg_lib.io.files import read_json\n",
    "from seg_lib.models.cafe_net.pvt import CAFE\n",
    "from seg_lib.models.pvt_v2 import SegPVT\n",
    "from seg_lib.models.selector import predictor_selector\n",
    "from seg_lib.models.normalizer import Normalizer\n",
    "from seg_lib.prompt import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf7d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.5\n",
    "# total number of parallel workers used in the dataloader\n",
    "N_CPUS = os.cpu_count()\n",
    "N_GPUS = torch.cuda.device_count()\n",
    "DEVICE = 'cuda' if N_GPUS > 0 else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36212e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'E:\\\\UNIPD\\\\SAM'\n",
    "TEST_PATH = f'{BASE_PATH}/data/test'\n",
    "TEST_DESCRIPTOR = 'metadata/ribs_test_old.csv'\n",
    "BASE_WEIGHTS = f'{BASE_PATH}/pretrained_models/pvt_v2_b2.pth'\n",
    "MODELS_SETS = [\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da2',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da2',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da2',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_small_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_small_da1',\n",
    "    ],\n",
    "    [\n",
    "        f'{BASE_PATH}/outputs/train/ribs_pvt_da1',\n",
    "        f'{BASE_PATH}/outputs/train/ribs_cafe_da1',\n",
    "    ]\n",
    "]\n",
    "SAM_WEIGHTS = f'{BASE_PATH}/pretrained_models/sam_vit_b_01ec64.pth'\n",
    "SAM_MODELS = [\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_small_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_da1/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_small_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v0_9_0_da2/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v1_1_0_small/best_SAMUS.pth',\n",
    "    f'{BASE_PATH}/outputs/train/v1_1_0/best_SAMUS.pth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_type: str, ckpt_path: str):\n",
    "    if model_type == 'pvt':\n",
    "        return SegPVT(backbone_ckpt_path=ckpt_path)\n",
    "    \n",
    "    return CAFE(pvtv2_path=ckpt_path)\n",
    "\n",
    "def get_model(ckpt_path: str, model_path: str, model_type: str = 'pvt'):\n",
    "    model = select_model(model_type, ckpt_path)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac66ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "        data_path: str,\n",
    "        data_desc_path: str,\n",
    "        batch_size: int = 8,\n",
    "        embedding_size: int = 128,\n",
    "        input_size: int = 352):\n",
    "    csv_path = os.path.join(data_path, data_desc_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    test_split = 'test' if 'test' in df['split'].unique() else 'val'\n",
    "    del df\n",
    "\n",
    "    test_dataset = SamGeneralDataset(\n",
    "        data_path,\n",
    "        split=test_split, \n",
    "        point_sampler=None,\n",
    "        df_file_path=data_desc_path,\n",
    "        img_size=input_size,\n",
    "        embedding_size=embedding_size,\n",
    "        prompt=None,\n",
    "        read_img_as_grayscale=False)\n",
    "    \n",
    "    return DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size * max(1, N_GPUS),\n",
    "        shuffle=False,\n",
    "        num_workers=N_CPUS,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0692024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_preds(preds):\n",
    "    if isinstance(preds, tuple):\n",
    "        final_preds = preds[0]\n",
    "        for i in range(1, len(preds)):\n",
    "            final_preds += preds[i]\n",
    "        preds = final_preds\n",
    "\n",
    "    return preds\n",
    "\n",
    "def eval(test_dataset, model_1, model_2):\n",
    "    metrics = Metrics()\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "    pred_masks = []\n",
    "    pred_logits = []\n",
    "    file_names = []\n",
    "    \n",
    "    data_config = {'dtype': torch.float32, 'device': DEVICE}\n",
    "    for batch in tqdm(test_dataset):\n",
    "        imgs = batch['image'].to(**data_config)\n",
    "        labels = batch['label'].to(**data_config)\n",
    "        orig_sizes = np.array(\n",
    "            list(zip(*batch['original_img_size']) ), dtype=int\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _start = time.time()\n",
    "            preds_1 = model_1(imgs)\n",
    "            preds_2 = model_2(imgs)\n",
    "            _end = time.time()\n",
    "\n",
    "        latency_p_batch.append(_end - _start)\n",
    "        batch_sizes.append(imgs.shape[0])\n",
    "\n",
    "        preds_1 = flatten_preds(preds_1)\n",
    "        preds_2 = flatten_preds(preds_2)\n",
    "        preds = (preds_1 + preds_2) / 2\n",
    "        \n",
    "        logits = preds.sigmoid().detach().numpy()[:, 0, :, :]\n",
    "        bin_masks = (logits > TH).astype('uint8')\n",
    "        labels = labels.detach().numpy()[:, 0, :, :].astype('uint8')\n",
    "        for i in range(bin_masks.shape[0]):\n",
    "            bin_mask = cv2.resize(\n",
    "                bin_masks[i], orig_sizes[i], cv2.INTER_NEAREST\n",
    "            )\n",
    "            label = cv2.resize(labels[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            metrics.step(bin_mask, label)\n",
    "\n",
    "            logits_i = cv2.resize(logits[i], orig_sizes[i], cv2.INTER_NEAREST)\n",
    "            pred_logits.append(logits_i)\n",
    "            pred_masks.append(bin_mask)\n",
    "            file_names.append(batch['img_name'][i])\n",
    "\n",
    "    metrics = {\n",
    "        **metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "    preds = {\n",
    "        file_names[i]: {\n",
    "            'logits': pred_logits[i],\n",
    "            'mask': pred_masks[i]\n",
    "        }\n",
    "        for i in range(len(file_names))\n",
    "    }\n",
    "    return metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aecac580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(i_row: dict):\n",
    "    base_path = os.path.join(TEST_PATH, i_row['subset']) \n",
    "    img_path = os.path.join(base_path, 'img', i_row['img_name'])\n",
    "    label_path = os.path.join(base_path, 'label', i_row['label_name'])\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        raise ValueError(f'Image does not exist on disk: {img_path}')\n",
    "    if not os.path.exists(label_path):\n",
    "        raise ValueError(f'Label does not exist on disk: {label_path}')\n",
    "\n",
    "    # load the image (H, W, 3) and convert it from BGR to RGB\n",
    "    image = cv2.imread(img_path, 1)[:, :, ::-1]\n",
    "    # read the mask as (H, W), grayscale\n",
    "    mask = cv2.imread(label_path, 0)\n",
    "    mask[mask > 1] = 1\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def predict_sam(data_df, predictor, sampler, seg_preds):\n",
    "    sam_metrics = Metrics()\n",
    "    preds = {}\n",
    "    batch_sizes = []\n",
    "    latency_p_batch = []\n",
    "\n",
    "    for _, row in tqdm(data_df.iterrows(), total=data_df.shape[0]):\n",
    "        img, label = read_img(row)        \n",
    "        mask_of_blobs = measure.label(seg_preds[row['img_name']]['mask'])\n",
    "        input_point, input_label = sampler.sample(\n",
    "            mask_of_blobs, seg_preds[row['img_name']]['mask']\n",
    "        )\n",
    "\n",
    "        _start = time.time()\n",
    "        predictor.set_image(img)\n",
    "        sam_logits, iou_scores, _ = predictor.predict(\n",
    "            point_coords=input_point,\n",
    "            point_labels=input_label,\n",
    "            multimask_output=False,\n",
    "            return_logits=True\n",
    "        )\n",
    "        _end = time.time()\n",
    "        batch_sizes.append(1)\n",
    "        latency_p_batch.append(_end - _start)\n",
    "\n",
    "        logits =  sam_logits[np.argmax(iou_scores)]\n",
    "        binary_mask = logits > 0.0\n",
    "        sam_metrics.step(binary_mask, label)\n",
    "\n",
    "        preds[row['img_name']] = {\n",
    "            'label': label,\n",
    "            'logits': Normalizer.sigmoid(logits).astype(np.float32)\n",
    "        }\n",
    "\n",
    "    sam_metrics = {\n",
    "        **sam_metrics.get_results(),\n",
    "        'fps': sum(batch_sizes) / sum(latency_p_batch),\n",
    "        'latency': sum(latency_p_batch) / sum(batch_sizes),\n",
    "        'latency_p_batch': sum(latency_p_batch) / len(batch_sizes)\n",
    "    }\n",
    "\n",
    "    return sam_metrics, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e389bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse(preds, sam_preds):\n",
    "    fusion_metrics = Metrics()\n",
    "    fusion_preds = {}\n",
    "    for img_name in preds:\n",
    "        fusion = LogitsFusion.apply(\n",
    "            preds[img_name]['logits'],\n",
    "            sam_preds[img_name]['logits'],\n",
    "            method='default')\n",
    "        fusion_preds[img_name] = { 'logits': fusion }\n",
    "        fusion_metrics.step(fusion > TH, sam_preds[img_name]['label'])\n",
    "    \n",
    "    return fusion_metrics.get_results(), fusion_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289190df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(TEST_PATH, TEST_DESCRIPTOR))\n",
    "test_ds = get_dataset(\n",
    "    TEST_PATH,\n",
    "    TEST_DESCRIPTOR,\n",
    "    batch_size=8,\n",
    "    embedding_size=128,\n",
    "    input_size=352)\n",
    "sampler = Sampler(\n",
    "    sampling_step=50,\n",
    "    min_blob_count=10,\n",
    "    mode='grid',\n",
    "    erode_grid='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4681b0-b891-4118-9dbc-fe890ff267c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\UNIPD\\\\SAM/outputs/train/ribs_pvt_small_da1', 'E:\\\\UNIPD\\\\SAM/outputs/train/ribs_cafe_small_da1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\gustavo\\miniconda3\\envs\\sam-v2\\lib\\site-packages\\torch\\nn\\functional.py:3782: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "100%|██████████| 7/7 [01:09<00:00,  9.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg. Metrics {'iou': 0.6204378660941883, 'dice': 0.7644125092063282, 'mae': 9.989186664486024, 'f-measure': 0.7488671886674982, 'e-measure': 0.901772510338703, 'fps': 0.8618318118397545, 'latency': 1.160319201800288, 'latency_p_batch': 8.122234412602015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:21<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6360637084708394, 'dice': 0.7768735194441058, 'mae': 9.048432445946698, 'f-measure': 0.7549317705489784, 'e-measure': 0.9046942609827254, 'fps': 0.3515353106050143, 'latency': 2.844664447161616, 'latency_p_batch': 2.844664447161616}\n",
      "Fusion Metrics {'iou': 0.6409931903576157, 'dice': 0.7800227726055444, 'mae': 9.739050742670903, 'f-measure': 0.7668036046733301, 'e-measure': 0.9080097325914086}\n",
      "['E:\\\\UNIPD\\\\SAM/outputs/train/ribs_pvt_da1', 'E:\\\\UNIPD\\\\SAM/outputs/train/ribs_cafe_da1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:56<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg. Metrics {'iou': 0.7461357452480621, 'dice': 0.8538623229118802, 'mae': 6.362168843005437, 'f-measure': 0.8455649588581431, 'e-measure': 0.9447117200033565, 'fps': 1.0827218201380575, 'latency': 0.9235982700270049, 'latency_p_batch': 6.465187890189035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:34<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.7080126979930932, 'dice': 0.8284067812642778, 'mae': 7.338039628605223, 'f-measure': 0.8162090164048258, 'e-measure': 0.9322124411575289, 'fps': 0.3220353704954169, 'latency': 3.1052489621298656, 'latency_p_batch': 3.1052489621298656}\n",
      "Fusion Metrics {'iou': 0.7558047330521354, 'dice': 0.8602138686596486, 'mae': 6.411769390678653, 'f-measure': 0.8540952186698397, 'e-measure': 0.9464095806998338}\n"
     ]
    }
   ],
   "source": [
    "full_preds = []\n",
    "full_sam_preds = []\n",
    "full_fusion_preds = []\n",
    "\n",
    "for i in range(len(MODELS_SETS)):\n",
    "    print(MODELS_SETS[i])\n",
    "    pvt_path = MODELS_SETS[i][0]\n",
    "    cafe_path = MODELS_SETS[i][1]\n",
    "\n",
    "    pvt_config = read_json(os.path.join(pvt_path, 'config.json'))\n",
    "    cafe_config = read_json(os.path.join(cafe_path, 'config.json'))\n",
    "\n",
    "    pvt_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(pvt_path, f\"best_{pvt_config['model_type']}.pth\"),\n",
    "        model_type='pvt')\n",
    "    cafe_model = get_model(\n",
    "        BASE_WEIGHTS,\n",
    "        os.path.join(cafe_path, f\"best_{cafe_config['model_type']}.pth\"),\n",
    "        model_type='cafe')\n",
    "    predictor = predictor_selector(\n",
    "        model_topology='SAMUS',\n",
    "        checkpoint_path=[SAM_WEIGHTS, SAM_MODELS[i]],\n",
    "        model_type='vit_b',\n",
    "        device=DEVICE)\n",
    "    \n",
    "    metrics, preds = eval(test_ds, pvt_model, cafe_model)\n",
    "    print('Seg. Metrics', metrics)\n",
    "    sam_metrics, sam_preds = predict_sam(test_df, predictor, sampler, preds)\n",
    "    print('SAM Metrics', sam_metrics)\n",
    "    fusion_metrics, fusion_preds = fuse(preds, sam_preds)\n",
    "    print('Fusion Metrics', fusion_metrics)\n",
    "\n",
    "    full_preds.append(preds)\n",
    "    full_sam_preds.append(sam_preds)\n",
    "    full_fusion_preds.append(fusion_preds)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08031ba",
   "metadata": {},
   "source": [
    "### Late Ensemble Model Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c435465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "small_da1_preds = full_preds[0]\n",
    "small_da2_preds = full_preds[2]\n",
    "small_fus_preds = {\n",
    "    _k: {\n",
    "        **small_da1_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_preds[_k]['logits'] + small_da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}\n",
    "\n",
    "small_da1_sam_preds = full_sam_preds[0]\n",
    "small_da2_sam_preds = full_sam_preds[2]\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            small_da1_sam_preds[_k]['logits']\n",
    "                + small_da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in small_da1_sam_preds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c5ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6602243498209209, 'dice': 0.7943975631104319, 'mae': 9.385327547340767, 'f-measure': 0.7836134115752975, 'e-measure': 0.9162794015060504}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, small_da3_preds = fuse(small_fus_preds, small_da1_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9af5765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1 + da2\n",
    "da1_preds = full_preds[1]\n",
    "da2_preds = full_preds[3]\n",
    "fus_preds = {\n",
    "    _k: {\n",
    "        **da1_preds[_k],\n",
    "        'logits': (\n",
    "            da1_preds[_k]['logits'] + da2_preds[_k]['logits']\n",
    "        ) / 2\n",
    "    }\n",
    "    for _k in da1_preds\n",
    "}\n",
    "\n",
    "da1_sam_preds = full_sam_preds[1]\n",
    "da2_sam_preds = full_sam_preds[3]\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': (\n",
    "            da1_sam_preds[_k]['logits']\n",
    "                + da2_sam_preds[_k]['logits']) / 2\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aba433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.7686429309002708, 'dice': 0.8684520701086881, 'mae': 5.111098781019195, 'f-measure': 0.8530498327533637, 'e-measure': 0.9467031925486953}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, da3_preds = fuse(fus_preds, fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a053a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samus_path = f'{BASE_PATH}/outputs/train/v1_1_0_small/best_SAMUS.pth'\n",
    "predictor = predictor_selector(\n",
    "    model_topology='SAMUS',\n",
    "    checkpoint_path=[SAM_WEIGHTS, samus_path],\n",
    "    model_type='vit_b',\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e819f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [02:52,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6358890626159537, 'dice': 0.7767126719795495, 'mae': 8.973565291054921, 'f-measure': 0.7539693235311709, 'e-measure': 0.9040754384652328, 'fps': 0.28949259309765196, 'latency': 3.4543198128135835, 'latency_p_batch': 3.4543198128135835}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sam_metrics, small_sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, small_fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c24993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6725449702235992, 'dice': 0.8033278654421616, 'mae': 8.306923982501816, 'f-measure': 0.7861679291655427, 'e-measure': 0.9173022302621321}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ef1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:31<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM Metrics {'iou': 0.6378849821719765, 'dice': 0.7782654476356223, 'mae': 9.104353290168705, 'f-measure': 0.7574649069311447, 'e-measure': 0.9068881372491581, 'fps': 0.3277945676507628, 'latency': 3.0506911910310084, 'latency_p_batch': 3.0506911910310084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sam_metrics, sam_da3_preds = predict_sam(\n",
    "    test_df, predictor, sampler, fus_preds)\n",
    "print('SAM Metrics', sam_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daa3abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.7705527010067807, 'dice': 0.8697553929427443, 'mae': 5.600976977547058, 'f-measure': 0.8595721182579256, 'e-measure': 0.9488832734141}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(fus_preds, sam_da3_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c33ec996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMUS 1+2+3\n",
    "fus_sam_preds = {\n",
    "    _k: {\n",
    "        **da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            da1_sam_preds[_k]['logits'],\n",
    "            da2_sam_preds[_k]['logits'],\n",
    "            sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in da1_sam_preds\n",
    "}\n",
    "small_fus_sam_preds = {\n",
    "    _k: {\n",
    "        **small_da1_sam_preds[_k],\n",
    "        'logits': np.mean([\n",
    "            small_da1_sam_preds[_k]['logits'],\n",
    "            small_da2_sam_preds[_k]['logits'],\n",
    "            small_sam_da3_preds[_k]['logits']\n",
    "        ], axis=0)\n",
    "    }\n",
    "    for _k in small_da1_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ed1992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Metrics {'iou': 0.6689124031586137, 'dice': 0.8007171744662946, 'mae': 8.47706125985157, 'f-measure': 0.7840170173855323, 'e-measure': 0.9165229807920677}\n"
     ]
    }
   ],
   "source": [
    "fusion_metrics, fusion_preds = fuse(small_fus_preds, small_fus_sam_preds)\n",
    "print('Fusion Metrics', fusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
